<!DOCTYPE html>
<html lang="pt-BR">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Processamento de Vídeo — Equipe</title>
<style>
  :root{
    --vinho:#751a32;
    --fundo-pagina:#eebbbb;
    --cinza:#e5e5e7;
    --texto:#222;
  }
  html,body{
    margin:0;
    padding:0;
    background:var(--fundo-pagina);
    color:var(--texto);
    font-family:Arial, Helvetica, sans-serif;
  }
  .hero{
    background:var(--vinho);
    color:#fff;
    text-align:center;
    padding:48px 16px 36px;
  }
  .hero h1{margin:0 0 8px;font-size:36px;}
  .hero h2{margin:6px 0 16px;font-size:22px;font-weight:700;}
  .hero .nomes{max-width:980px;margin:0 auto;opacity:.95;}
  .container{
    max-width:980px;
    margin:28px auto 48px;
    padding:0 16px;
  }
  .tema{
    font-weight:700;
    font-size:18px;
    margin:32px 0 12px;
  }
  details{
    background:#fff;
    border-radius:6px;
    margin:8px 0;
    border:1px solid #ddd;
    overflow:hidden;
  }
  summary{
    list-style:none;
    cursor:pointer;
    padding:12px 14px;
    font-weight:700;
    background:#fff;
    color:var(--texto);
    display:flex; align-items:center; gap:8px;
    user-select:none;
  }
  summary::before{content:"►";font-weight:900;color:var(--texto);}
  details[open] summary::before{content:"▼";}
  .content{
    padding:12px 14px 14px;
    line-height:1.6;
    background:#fff;
    color:var(--texto);
    border-top:1px solid #eee;
  }
  .refs a{
    display:inline-block;
    margin:4px 10px 4px 0;
    text-decoration:none;
    color:#fff;
    background:var(--vinho);
    padding:8px 12px;
    border-radius:8px;
    font-weight:700;
  }
  .refs a:hover{filter:brightness(.92);}
  .footer{
    background:var(--cinza);
    color:#111;
    text-align:center;
    padding:18px 12px;
    font-size:14px;
  }
  summary:focus{outline:3px solid #00000022;outline-offset:2px;}
</style>
</head>
<body>

  <header class="hero">
    <h1>Processamento de Vídeo</h1>
    <h2>Equipe</h2>
    <div class="nomes">
      Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier 
    </div>
  </header>

  <div class="container">
    <div class="tema">Tema: Monitoramento do uso de celular na direção</div>

    <!-- ETAPA 1 -->
    <details open>
      <summary>ETAPA 1: Contexto e Cenário de Aplicação (CA)</summary>
      <div class="content">
        <p>Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier</p>
        <p><strong>Data:</strong> 01/10/2025</p>

        <h3>Introdução</h3>
        <div style="font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;">
        <p>A distração ao volante é um dos principais fatores que elevam o risco de acidentes de trânsito nos dias atuais, especialmente com o crescimento do uso de celulares. Segundo pesquisas da OMS e de outras organizações, o uso do celular enquanto dirige pode aumentar o risco de colisões em até 400%. No Brasil, essa prática já figura como a terceira maior causa de mortes no trânsito, assim já podemos perceber o perigoso efeito de dirigir distraído mexendo ou olhando no celular pode impactar.</p>
        <p>Em termos de infrações entre 2023 e 2024, mais de 50 mil condutores foram autuados por uso de celular ao volante — o que corresponde a uma média de quase 150 flagrantes por dia. Agora, olhando pelo  ponto de vista internacional, os dados mostram essa tendência de risco elevado, como por exemplo: nos Estados Unidos, em 2023, 3.275 pessoas morreram em acidentes em que a distração estava envolvida. Além disso, cerca de 12% dos acidentes fatais ao redor do mundo, praticamente todos estavam relacionados a distrações envolvendo o uso de telefone celular enquanto dirigem. Ainda, diversos estudos mostram ainda que tarefas visuais e manuais (como digitar ou deslizar no celular) estão entre as que mais aumentam o risco de acidentes de trânsito.</p>

        <p>O uso de celular ao volante é uma das principais causas de distração e acidentes, pois reduz o tempo de reação e aumenta o risco de colisões, colocando em perigo motoristas, passageiros e pedestres. Entrevistas empáticas com condutores e acompanhantes confirmaram que a distração pelo celular é frequente e que há consenso sobre a necessidade de um sistema de alerta rápido que mantenha a privacidade do usuário. Diante disso, este trabalho propõe um Sistema de Processamento de Vídeo (SPV), desenvolvido em C++ com a biblioteca OpenCV, que capta e analisa em tempo real as imagens do motorista. Ao identificar gestos típicos de uso do celular, como segurar o aparelho ou olhar para baixo, o sistema emite alerta sonoro e visual, incentivando o condutor a retomar a atenção. Além de aumentar a segurança e a conscientização, o projeto aplica conceitos da disciplina, como filtragem de imagens, processamento de cores, equalização de histograma, subtração de fundo e detecção de objetos, demonstrando aplicação prática e relevância social.</p>

        <h3>Etapas de desenvolvimento</h3>
        <h4>(A) Problema a ser abordado</h4>
        <p>Dentro do conteúdo da disciplina de Processamento de Vídeo, a RoadWatch, será um aplicativo cujo a sua principal função é detectar automaticamente o uso do celular enquanto o motorista dirige. </p>

<p><strong>Justificativa:</strong> Desenvolver um sistema que identifique automaticamente o uso do celular durante a condução contribui para a redução de acidentes, atende às recomendações de segurança viária e aproveita técnicas de processamento de vídeo e visão computacional abordadas na disciplina.</p>
        <h4>(B) Objetivo</h4>
    <div style="font-family: Arial, sans-serif; line-height: 1.5;">
  <p>Criar um Sistema de Processamento de Vídeo (SPV) capaz de:</p>
  <ul>
    <li><strong>Captura de vídeo:</strong> o RoadWatch utiliza a câmera frontal do veículo (ou do próprio smartphone fixado no painel ou no para‐brisa) para captar imagens contínuas do rosto, mãos e ambiente à frente do condutor. </li>
   <li><strong>Pré-processamento:</strong> as imagens são filtradas (redução de ruído, ajuste de brilho/contraste, normalização) e recortadas nas regiões de interesse (por exemplo, face, mãos, volante).</li>
   <li><strong>Detecção de objetos / poses:</strong> algoritmos identificam, nos frames, os elementos-chave — como a mão segurando um smartphone, a face do motorista e a posição da cabeça — por meio de técnicas de detecção baseadas em redes neurais ou modelos clássicos.</li>
   <li><strong>Classificação de ação / comportamento:</strong> com base em sequências de frames e características extraídas (ângulos de flexão de dedos, deslocamentos da mão, direção do olhar, tempo de fixação), o sistema classifica comportamentos em “uso do celular” ou “comportamento seguro”. Modelos de aprendizado de máquina (SVM, árvores, redes neurais profundas) treinados com datasets anotados são empregados para essa tarefa.</li>
   <li><strong>Alerta em tempo real:</strong> quando o sistema detecta um padrão de risco (por exemplo, digitação, deslize, olhar prolongado para celular), ele emite um alerta audiovisual ou vibratório para chamar a atenção do motorista e inibir a continuidade da distração.   </li>
   <li><strong>Registro e logging:</strong> o app registra os eventos detectados (tempo, tipo de distração, duração) para posterior análise, avaliação e refinamento do modelo.   </li>

  </ul>
</div>

        <h4>(C) Funcionamento do Sistema</h4>
        <p>O sistema inicia seu funcionamento assim que o motorista liga o veículo e aciona o programa instalado em um computador de bordo, notebook ou minipc conectado a uma webcam posicionada próxima ao retrovisor. A câmera capta continuamente as imagens do motorista, incluindo rosto, mãos e a região do colo, enviando-as em tempo real para o módulo de processamento em C++ com a biblioteca OpenCV. Primeiramente, os quadros do vídeo passam por etapas de pré-processamento, como filtragem e equalização de histograma, para garantir boa qualidade mesmo sob variações de iluminação. Em seguida, é aplicada a subtração de fundo para isolar os elementos em movimento e facilitar a análise de postura e gestos.</p>

<p>Com a cena preparada, os algoritmos de detecção de objetos e de análise de movimento identificam regiões correspondentes ao rosto e às mãos. O sistema compara continuamente a posição e os gestos detectados com padrões típicos do uso de celular, como a mão erguida próximo ao ouvido, o olhar direcionado para baixo ou o ato de segurar um aparelho retangular. Quando essas características coincidem com o veículo em movimento, o programa aciona de imediato um alerta sonoro e visual na tela, chamando a atenção do condutor para retomar o foco na direção.</p>

<p>Todos os eventos são contabilizados, permitindo gerar ao final da viagem um resumo com estatísticas de tempo de distração e quantidade de alertas emitidos. Todo o processamento é feito localmente, sem envio de imagens para a nuvem, preservando a privacidade do usuário. Assim, o sistema atua de maneira autônoma e em tempo real, combinando captura, análise e notificação instantânea para prevenir acidentes causados pelo uso do celular durante a condução.</p>

 <h4> Exemplo de Uso Prático</h4>
 <div style="font-family: Arial, sans-serif; line-height: 1.5;">
 <p>Imagine que um motorista está trafegando a 60 km/h em via urbana e recebe uma mensagem de texto. Ao decidir verificar o celular, ele levanta o olhar, a visão frontal se perde por cerca de 1,5 segundos, enquanto a mão se desloca à lateral. O RoadWatch identifica:</p>
 <ul>
    <li>movimento da mão em direção ao painel (rastreado por vários frames); </li>
   <li>presença do smartphone na mão (detecção de objeto);</li>
   <li>desvio do olhar (rosto/inclinação da cabeça);</li>
   <li>padrão temporal de digitação (movimento repetitivo dos dedos sobre a tela).</li>
  </ul>
</div>

<p>O modelo classifica essa sequência como “distração com uso de celular” e dispara um alerta sonoro e visual antes que o comportamento perdure ou cause risco elevado.</p>
 
        <h4>(D) Benefícios esperados</h4>
        <div style="font-family: Arial, sans-serif; line-height: 1.5;">
  <ul>
    <li><strong>Segurança:</strong> reduz riscos de acidentes ao alertar sobre distrações.</li>
    <li><strong>Conscientização:</strong> o relatório de uso reforça hábitos de direção segura.</li>
    <li><strong>Baixo custo e simplicidade:</strong> utiliza apenas uma câmera e processamento local, dispensando internet.</li>
    <li><strong>Integração acadêmica: </strong> o RoadWatch conecta diretamente os conceitos abordados na disciplina (filtragem, segmentação, rastreamento, classificação) com um caso de uso real e socialmente relevante.</li>
  </ul>
</div>

    <h4>Considerações práticas e limitações:</h4>
 <ul>
    <li>A qualidade da câmera (resolução, iluminação, ângulo) impacta fortemente a precisão da detecção.</li>
  <li>Condições adversas (baixa luminosidade, reflexos, mãos encobertas, uso de capa de telefone) podem dificultar a classificação.</li>
  <li>A latência de processamento precisa ser mínima para que o alerta seja efetivo, o que impõe requisitos de desempenho.
Cuidados com privacidade e consentimento são essenciais se o app gravar ou armazenar imagens do condutor.</li>


        <h3>Referências</h3>
        <ul>
          <li>Entrevistas Fernanda</li>
          <li>Entrevistas Gabriel</li>
          <li>Entrevistas Ingrid</li>
        </ul>
        <div class="refs">
          <a href="downloads/Entrevistas_Fernanda.pdf" download>Download Entrevistas Fernanda</a>
          <a href="downloads/Entrevistas_Gabriel.pdf" download>Download Entrevistas Gabriel</a>
          <a href="file:///home/ingrid/PV/Entrevistas_Ingrid.pdf" download>Download Entrevistas Ingrid</a>
        </div>
      </div>
    </details>

    <!-- ETAPA 2 -->
    <details>
      <summary>ETAPA 2: Modelagem Funcional do Sistema (MF)</summary>
      <div class="content">
        <p>Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier </p>
        <p><strong>Data:</strong> 08/10/2025</p>

        <h3>Descrição Geral</h3>
        <div style="font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;">
        <p>O sistema proposto tem como finalidade monitorar, em tempo real, o uso de celular pelo motorista e emitir alerta sonoro e visual sempre que detectar um comportamento de distração. Desenvolvido em C++ com a biblioteca OpenCV e executado em ambiente Ubuntu Linux, ele funciona em três etapas encadeadas. Na primeira, a webcam capta continuamente a imagem do condutor, enquanto cada quadro é filtrado e tem cores e histograma ajustados, com subtração de fundo para realçar rosto e mãos. Em seguida, algoritmos de detecção de objetos e análise de movimento identificam gestos característicos do uso de celular, como segurar o aparelho próximo ao ouvido ou olhar para baixo. Por fim, quando o veículo está em movimento e um desses gestos é reconhecido, o sistema aciona de imediato os alertas e registra métricas de desempenho, como acertos, falsos positivos e falsos negativos, para avaliação posterior. Todo o processamento é realizado localmente, garantindo a privacidade do usuário e exigindo apenas que o programa seja iniciado no início da viagem.
</p>

        <h3>Diagrama de Blocos - Modelagem Funcional</h3>
<figure>
  <img src="Diagrama_de_Blocos.png" alt="Fluxograma do sistema de detecção de uso de celular em veículo em movimento, mostrando as etapas de captura de imagem, processamento, detecção de comportamento, verificação de movimento e geração de alertas." style="max-width:90%; height:auto;">
</figure>

</body>
</html>



        <h4>Descrição dos Blocos Funcionais</h4>
        <p></p>

        <h4>Estimativa do uso de técnicas para o projeto</h4>
        <p></p>

        <h4>Conclusão</h4>
        <p></p>
      </div>
    </details>

    <!-- ETAPA 3 -->
    <details>
      <summary>ETAPA 3: Seminário S1 do Trabalho</summary>
      <div class="content">
        <div class="refs">
          <a href="downloads/seminarios1.pdf" download>Download Seminário S1</a>
        </div>
      </div>
    </details>

    <!-- ETAPA 4 -->
    <details>
      <summary>ETAPA 4: Desenvolvimento do Sistema de Processamento da Visão (SPV)</summary>
      <div class="content">Coloque aqui o conteúdo da Etapa 4.</div>
    </details>

    <!-- ETAPA 5 -->
    <details>
      <summary>ETAPA 5: Desenvolvimento do laboratório experimental (LEx)</summary>
      <div class="content">
        <p>Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier </p>
        <p><strong>Data:</strong> 12/11/2025</p>

        <h3>Objetivo</h3>
        <p>
          Preparar o Teste de Campo (TC) do Sistema de Processamento Visual (SPV), por meio da
          elaboração do Laboratório Experimental (LEx), atendendo às condições e roteiros definidos abaixo.
        </p>

        <h3>Roteiro do Laboratório Experimental (para cada aplicação)</h3>
        <ul>
          <li>Roteiro de procedimento experimental com instruções claras para executar o sistema e coletar resultados.</li>
          <li>Figuras/imagens que esclareçam o procedimento e os resultados esperados.</li>
        </ul>

        <h3>Introdução</h3>
        <p><!-- explicar funcionamento do sistema, telas e interfaces; como um usuário leigo opera --></p>

        <h3>Procedimento experimental</h3>
        <p><!-- instruções detalhadas; incluir figuras/imagens se necessário --></p>

        <h3>Questionário de avaliação do usuário</h3>
        <ul>
          <li>(i) Entendeu o assunto por meio do experimento?</li>
          <li>(ii) Obteve resultados esperados?</li>
          <li>(iii) Entendeu a aplicação do sistema?</li>
        </ul>

        <h3>Notas e planilha de médias</h3>
        <ul>
          <li>Atribuir nota por questão; calcular média por usuário em planilha (Excel/Office).</li>
          <li>Enviar a planilha pelo Moodle após o TC do SPV.</li>
        </ul>

        <h3>Enquete Subjetiva de Opinião (ESO)</h3>
        <ul>
          <li>Perguntas abertas (respostas escritas).</li>
          <li>Perguntas com escala 1–5 (avaliar opinião do usuário).</li>
        </ul>
      </div>
    </details>

    <!-- ETAPA 6 -->
    <details>
      <summary>ETAPA 6: Teste de Campo do SPV (TC)</summary>
      <div class="content">Coloque aqui o conteúdo da Etapa 6.</div>
    </details>

    <!-- ETAPA 7 -->
    <details>
      <summary>ETAPA 7: Relatório Final do Trabalho (RFT)</summary>
      <div class="content">
        <p>Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier </p>
        <p><strong>Data:</strong> 24/11/2025</p>

        <h3>Introdução</h3>
        <ul>
          <li><strong>Objetivos do trabalho</strong> — <!-- descreva os objetivos principais e específicos --></li>
        </ul>

        <h3>Cenário de Aplicação (CA)</h3>
        <p><!-- descreva o contexto, público-alvo, ambiente de uso e riscos/necessidades --></p>

        <h3>Fundamentação teórica</h3>
        <p><!-- teorias, métodos, trabalhos relacionados e referências principais --></p>

        <h3>Materiais e métodos</h3>

        <h4>Modelagem Funcional do SPV (MF)</h4>
        <p><!-- apresente o diagrama de blocos e o papel de cada bloco funcional --></p>

        <h4>Descrição da implementação do Sistema de Processamento da Visão (SPV)</h4>
        <p><!-- algoritmos, bibliotecas, pipeline de processamento, parâmetros relevantes --></p>

        <h4>Lista dos arquivos</h4>
        <ul>
          <li><strong>Códigos-fonte</strong>: <!-- ex.: /src, /notebooks --></li>
          <li><strong>Imagens</strong>: <!-- ex.: /data/images --></li>
          <li><strong>Vídeos</strong>: <!-- ex.: /data/videos --></li>
          <li><strong>Arquivos auxiliares</strong>: <!-- ex.: pesos, configs, rótulos --></li>
        </ul>

        <h4>Análise técnica (grau de atendimento ao contexto/cenário)</h4>
        <ul>
          <li><strong>Métricas objetivas</strong> (numéricas): <!-- precisão, sensibilidade, etc. --></li>
          <li><strong>Métricas qualitativas</strong>: <!-- avaliação de usabilidade, feedback de usuários --></li>
          <li><strong>Resultados e conclusões parciais</strong>: <!-- destaque achados principais --></li>
        </ul>

        <h3>Laboratório Experimental</h3>

        <h4>Roteiro do Laboratório Experimental (LEx)</h4>
        <p><!-- passos, equipamentos, condições de teste, critérios de parada --></p>

        <h4>Análise dos Resultados do Teste de Campo (TC)</h4>
        <ul>
          <li><strong>Descrição dos experimentos</strong>: <!-- detalhe cada experimento realizado --></li>
          <li><strong>Critérios de avaliação</strong>: <!-- métricas, escalas e thresholds usados --></li>
          <li><strong>Médias dos alunos</strong>: <!-- como foram calculadas e interpretadas --></li>
          <li><strong>Opiniões subjetivas</strong>: <!-- observações qualitativas --></li>
        </ul>

        <h3>Conclusões</h3>
        <p><!-- comente se objetivos e modelagem foram atingidos; pontos positivos/negativos --></p>

        <h3>Referências Bibliográficas</h3>
        <ul>
          <li><!-- AUTOR. Título. Editora/Conferência, ano. DOI/URL. --></li>
        </ul>

        <h3>Anexo</h3>
        <p><!-- incluir códigos completos e todos os arquivos relevantes (ou links de download) --></p>
      </div>
    </details>

    <!-- ETAPA 8 -->
    <details>
      <summary>ETAPA 8: Seminário S2 do Trabalho</summary>
      <div class="content">
        <div class="refs">
          <a href="downloads/seminarios2.pdf" download>Download Seminário S2</a>
        </div>
      </div>
    </details>
  </div>

  <footer class="footer">
    © 2025 — Equipe
  </footer>
</body>
</html>
