<!DOCTYPE html>
<html lang="pt-BR">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Processamento de Vídeo</title>
<style>
  :root{
    --vinho:#751a32;
    --fundo-pagina:#eebbbb;
    --cinza:#e5e5e7;
    --texto:#222;
  }
  html,body{
    margin:0;
    padding:0;
    background:var(--fundo-pagina);
    color:var(--texto);
    font-family:Arial, Helvetica, sans-serif;
    scroll-behavior:smooth;
  }
  .hero{
    background:var(--vinho);
    color:#fff;
    text-align:center;
    padding:48px 16px 24px;
  }
  .hero h1{margin:0 0 8px;font-size:36px;}
  .hero h2{margin:6px 0 16px;font-size:22px;font-weight:700;}
  .hero .nomes{max-width:980px;margin:0 auto 10px;opacity:.95;}

  .nav{
    display:flex; gap:10px; justify-content:center; flex-wrap:wrap;
    padding:12px; background:#ffffff22;
  }
  .nav a{
    text-decoration:none; color:#fff; background:var(--vinho);
    padding:8px 12px; border-radius:8px; font-weight:700;
  }
  .nav a:hover{ filter:brightness(.92); }

  .container{
    max-width:980px;
    margin:28px auto 48px;
    padding:0 16px;
  }
  .tema{
    font-weight:700;
    font-size:18px;
    margin:32px 0 12px;
  }
  details{
    background:#fff;
    border-radius:6px;
    margin:8px 0;
    border:1px solid #ddd;
    overflow:hidden;
  }
  summary{
    list-style:none;
    cursor:pointer;
    padding:12px 14px;
    font-weight:700;
    background:#fff;
    color:var(--texto);
    display:flex; align-items:center; gap:8px;
    user-select:none;
  }
  summary::before{content:"►";font-weight:900;color:var(--texto);}
  details[open] summary::before{content:"▼";}
  .content{
    padding:12px 14px 14px;
    line-height:1.6;
    background:#fff;
    color:var(--texto);
    border-top:1px solid #eee;
  }
  .refs a{
    display:inline-block;
    margin:4px 10px 4px 0;
    text-decoration:none;
    color:#fff;
    background:var(--vinho);
    padding:8px 12px;
    border-radius:8px;
    font-weight:700;
  }
  .refs a:hover{filter:brightness(.92);}
  .footer{
    background:var(--cinza);
    color:#111;
    text-align:center;
    padding:18px 12px;
    font-size:14px;
  }
  summary:focus{outline:3px solid #00000022;outline-offset:2px;}
  .section-title{
    margin:0;
    padding:8px 0 0;
    font-size:26px;
    font-weight:800;
    color:#3b0f1e;
  }
  .back-top{
    text-align:right; margin:12px 0 24px;
  }
  .back-top a{
    text-decoration:none; font-weight:700; color:#3b0f1e;
  }
</style>
</head>
<body>

  <!-- HERO + NAV GLOBAL -->
  <header class="hero" id="topo">
    <h1>Processamento de Vídeo</h1>
    <h2>Equipe RoadWatch</h2>
    <div class="nomes">
      Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier
    </div>
    <nav class="nav" aria-label="Navegação principal">
      <a href="#equipe">Página inicial</a>
      <a href="#fernanda">Fernanda</a>
      <a href="#gabriel">Gabriel</a>
      <a href="#ingrid">Ingrid</a>
      <a href="#relatorios">Relatórios</a><!-- NOVA ABA -->
    </nav>
  </header>

  <!-- =========================
       SEÇÃO: EQUIPE (HOME)
  ========================== -->
  <section id="equipe" class="container" aria-labelledby="titulo-equipe">
    <div class="tema">Tema: Monitoramento do uso de celular na direção veicular.</div>

    <!-- ETAPA 1 -->
    <details>
      <summary>ETAPA 1: Contexto e Cenário de Aplicação (CA)</summary>
      <div class="content">
        <p>Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier</p>
        <p><strong>Data:</strong> 01/10/2025</p>

        <h3>Introdução</h3>
        <div style="font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;">
          <p>A distração ao volante é um dos principais fatores que elevam o risco de acidentes de trânsito nos dias atuais, especialmente com o crescimento do uso de celulares. Segundo pesquisas da OMS e de outras organizações, o uso do celular enquanto dirige pode aumentar o risco de colisões em até 400%. No Brasil, essa prática já figura como a terceira maior causa de mortes no trânsito, assim já podemos perceber o perigoso efeito de dirigir distraído mexendo ou olhando no celular pode impactar.</p>
          <p>Em termos de infrações entre 2023 e 2024, mais de 50 mil condutores foram autuados por uso de celular ao volante — o que corresponde a uma média de quase 150 flagrantes por dia. Agora, olhando pelo  ponto de vista internacional, os dados mostram essa tendência de risco elevado, como por exemplo: nos Estados Unidos, em 2023, 3.275 pessoas morreram em acidentes em que a distração estava envolvida. Além disso, cerca de 12% dos acidentes fatais ao redor do mundo, praticamente todos estavam relacionados a distrações envolvendo o uso de telefone celular enquanto dirigem. Ainda, diversos estudos mostram ainda que tarefas visuais e manuais (como digitar ou deslizar no celular) estão entre as que mais aumentam o risco de acidentes de trânsito.</p>

          <p>O uso de celular ao volante é uma das principais causas de distração e acidentes, pois reduz o tempo de reação e aumenta o risco de colisões, colocando em perigo motoristas, passageiros e pedestres. Entrevistas empáticas com condutores e acompanhantes confirmaram que a distração pelo celular é frequente e que há consenso sobre a necessidade de um sistema de alerta rápido que mantenha a privacidade do usuário. Diante disso, este trabalho propõe um Sistema de Processamento de Vídeo (SPV), desenvolvido em C++ com a biblioteca OpenCV, que capta e analisa em tempo real as imagens do motorista. Ao identificar gestos típicos de uso do celular, como segurar o aparelho ou olhar para baixo, o sistema emite alerta sonoro e visual, incentivando o condutor a retomar a atenção. Além de aumentar a segurança e a conscientização, o projeto aplica conceitos da disciplina, como filtragem de imagens, processamento de cores, equalização de histograma, subtração de fundo e detecção de objetos, demonstrando aplicação prática e relevância social.</p>
        </div>

        <h3>Etapas de desenvolvimento</h3>
        <h4>(A) Problema a ser abordado</h4>
        <p>Dentro do conteúdo da disciplina de Processamento de Vídeo, a RoadWatch, será um aplicativo cujo a sua principal função é detectar automaticamente o uso do celular enquanto o motorista dirige. </p>

        <p><strong>Justificativa:</strong> Desenvolver um sistema que identifique automaticamente o uso do celular durante a condução contribui para a redução de acidentes, atende às recomendações de segurança viária e aproveita técnicas de processamento de vídeo e visão computacional abordadas na disciplina.</p>

        <h4>(B) Objetivo</h4>
        <div style="font-family: Arial, sans-serif; line-height: 1.5;">
          <p>Criar um Sistema de Processamento de Vídeo (SPV) capaz de:</p>
          <ul>
            <li><strong>Captura de vídeo:</strong> o RoadWatch utiliza a câmera frontal do veículo (ou do próprio smartphone fixado no painel ou no para‐brisa) para captar imagens contínuas do rosto, mãos e ambiente à frente do condutor.</li>
            <li><strong>Pré-processamento:</strong> as imagens são filtradas (redução de ruído, ajuste de brilho/contraste, normalização) e recortadas nas regiões de interesse (por exemplo, face, mãos, volante).</li>
            <li><strong>Detecção de objetos / poses:</strong> algoritmos identificam, nos frames, os elementos-chave — como a mão segurando um smartphone, a face do motorista e a posição da cabeça — por meio de técnicas de detecção baseadas em redes neurais ou modelos clássicos.</li>
            <li><strong>Classificação de ação / comportamento:</strong> com base em sequências de frames e características extraídas (ângulos de flexão de dedos, deslocamentos da mão, direção do olhar, tempo de fixação), o sistema classifica comportamentos em “uso do celular” ou “comportamento seguro”.</li>
            <li><strong>Alerta em tempo real:</strong> quando o sistema detecta um padrão de risco, ele emite um alerta audiovisual ou vibratório.</li>
            <li><strong>Registro e logging:</strong> o app registra os eventos detectados (tempo, tipo de distração, duração) para posterior análise.</li>
          </ul>
        </div>

        <h4>(C) Funcionamento do Sistema</h4>
        <p>O sistema inicia seu funcionamento assim que o motorista liga o veículo e aciona o programa instalado em um computador de bordo, notebook ou minipc conectado a uma webcam posicionada próxima ao retrovisor...</p>

        <h4>Exemplo de Uso Prático</h4>
        <div style="font-family: Arial, sans-serif; line-height: 1.5;">
          <p>Imagine que um motorista está trafegando a 60 km/h em via urbana e recebe uma mensagem de texto...</p>
          <ul>
            <li>movimento da mão em direção ao painel;</li>
            <li>presença do smartphone na mão;</li>
            <li>desvio do olhar;</li>
            <li>padrão temporal de digitação.</li>
          </ul>
        </div>

        <h4>(D) Benefícios esperados</h4>
        <div style="font-family: Arial, sans-serif; line-height: 1.5;">
          <ul>
            <li><strong>Segurança:</strong> reduz riscos de acidentes ao alertar sobre distrações.</li>
            <li><strong>Conscientização:</strong> o relatório de uso reforça hábitos de direção segura.</li>
            <li><strong>Baixo custo e simplicidade:</strong> usa câmera e processamento local.</li>
            <li><strong>Integração acadêmica:</strong> conecta os conceitos da disciplina a um caso real.</li>
          </ul>
        </div>

        <h4>Considerações práticas e limitações:</h4>
        <ul>
          <li>Qualidade da câmera impacta a precisão.</li>
          <li>Condições adversas dificultam a classificação.</li>
          <li>Latência precisa ser mínima.</li>
          <li>Privacidade e consentimento se gravar imagens.</li>
        </ul>

        <h3>Referências</h3>
        <ul>
          <li>Entrevistas Fernanda</li>
          <li>Entrevistas Gabriel</li>
          <li>Entrevistas Ingrid</li>
        </ul>

        <div class="refs" style="display:flex; gap:12px; flex-wrap:wrap;">
          <a href="./Entrevistas_Fernanda.pdf" target="_blank" rel="noopener">Abrir Entrevistas Fernanda (PDF)</a>
          <a href="./Entrevistas_Gabriel.pdf" target="_blank" rel="noopener">Abrir Entrevistas Gabriel (PDF)</a>
          <a href="./Entrevistas_Ingrid.pdf" target="_blank" rel="noopener">Abrir Entrevistas Ingrid (PDF)</a>
        </div>

      </div><!-- FIM do .content da ETAPA 1 -->
    </details><!-- FIM do <details> da ETAPA 1 -->

    <!-- ETAPA 2 -->
      <details>
        <summary>ETAPA 2: Modelagem Funcional do Sistema (MF)</summary>
        <div class="content">
          <p>Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier</p>
          <p><strong>Data:</strong> 13/10/2025</p>
      
          <h3>Descrição Geral</h3>
          <div style="font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;">
            <p>
              O RoadWatch é um sistema de monitoramento inteligente que tem como objetivo 
              identificar, em tempo real, se o motorista está utilizando o celular enquanto dirige. 
              A proposta busca reduzir acidentes causados por distrações no trânsito, 
              detectando o comportamento do condutor através de uma câmera instalada no veículo. 
              O sistema analisa continuamente o vídeo capturado, verificando padrões como 
              posição das mãos, olhar do motorista e presença de um celular em cena.
            </p>
            <p>
              Durante a modelagem funcional, foram definidos os blocos principais que compõem 
              o funcionamento do sistema, bem como as entradas, saídas e processamentos de cada um. 
              Essa concepção funcional orienta o desenvolvimento de cada módulo de software e 
              auxilia na integração entre câmera e sensores e o processamento digital.
            </p>
          </div>
      
          <h3>Diagrama de Blocos - Modelagem Funcional</h3>
          <figure>
            <img src="imagens/Diagrama de Blocos RoadWatch.png" alt="Diagrama de blocos do sistema RoadWatch, mostrando os módulos de captura de imagem, pré-processamento, detecção de objetos, análise de comportamento e geração de alerta." style="max-width:100%; height:auto;">
            <figcaption>Figura 1 – Diagrama de blocos do sistema RoadWatch.</figcaption>
          </figure>
      
          <h4>Descrição dos Blocos Funcionais</h4>
          <div style="font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;">
            <ol>
              <li>
                <strong>Bloco 1 – Captura de Imagem</strong><br>
                Entrada: vídeo em tempo real da câmera frontal voltada ao motorista.<br>
                Processamento: coleta contínua de quadros (frames) com resolução suficiente para detecção de rosto e mãos, 
                ajustando taxa de quadros e brilho automaticamente conforme as condições de iluminação.<br>
                Saída: sequência de frames de vídeo prontos para pré-processamento.
              </li><br>
      
              <li>
                <strong>Bloco 2 – Pré-processamento de Imagem</strong><br>
                Entrada: frames capturados pelo módulo anterior.<br>
                Processamento: redimensionamento, normalização, correção de iluminação, 
                e definição de uma Região de Interesse focada na cabeça e mãos do motorista. 
                Essa etapa reduz ruídos e o custo computacional da análise.<br>
                Saída: imagens tratadas e otimizadas para detecção.
              </li><br>
      
              <li>
                <strong>Bloco 3 – Detecção de Objetos e Posições</strong><br>
                Entrada: imagens pré-processadas.<br>
                Processamento: aplicação de modelo de detecção baseado em redes neurais, identificando a localização da face, das mãos e do celular. 
                Cada detecção retorna uma coordenada e uma pontuação de confiança.<br>
                Saída: mapa de detecções e suas respectivas probabilidades.
              </li><br>
      
              <li>
                <strong>Bloco 4 – Análise de Comportamento do Motorista</strong><br>
                Entrada: resultados de detecção dos frames e histórico recente de posições.<br>
                Processamento: análise temporal dos frames para verificar gestos ou ações típicas 
                do uso de celular, como olhar para baixo ou segurar o telefone. 
                Pode ser utilizada uma rede de classificação de ações ou um filtro temporal.<br>
                Saída: rótulo de comportamento (ex.: “atento”, “usando celular”, “mão próxima ao rosto”).
              </li><br>
      
              <li>
                <strong>Bloco 5 – Verificação de Movimento do Veículo</strong><br>
                Entrada: dados de sensores como o GPS.<br>
                Processamento: determina se o veículo está em movimento acima de uma velocidade mínima 
                (ex.: 5 km/h), evitando que o alerta seja acionado com o carro parado.<br>
                Saída: estado do veículo (“em movimento” / “parado”).
              </li><br>
      
              <li>
                <strong>Bloco 6 – Fusão de Informações e Decisão</strong><br>
                Entrada: resultados da análise de comportamento e estado do veículo.<br>
                Processamento: combina os resultados, aplicando regras lógicas e filtros temporais 
                (por exemplo, exigir que o comportamento seja detectado em 3 frames consecutivos 
                para confirmar o evento).<br>
                Saída: decisão final (“alerta” ou “seguro”).
              </li><br>
      
              <li>
                <strong>Bloco 7 – Geração de Alertas e Registro</strong><br>
                Entrada: sinal de alerta gerado pelo módulo de decisão.<br>
                Processamento: aciona o alerta sonoro e/ou visual no painel do veículo 
                e registra o evento no log com data, hora e tipo de distração.<br>
                Saída: feedback imediato ao motorista e registro do incidente.
              </li>
            </ol>
          </div>
      
          <h4>Conclusão</h4>
          <div style="font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;">
            <p>
              A modelagem funcional do RoadWatch define claramente as etapas envolvidas 
              na identificação de distrações do motorista, desde a captura das imagens até 
              a emissão do alerta. A decomposição em blocos facilita o desenvolvimento modular, 
              a validação individual de cada componente e a futura integração com hardware real.
            </p>
            <p>
              Essa abordagem garante que o sistema possa evoluir de forma estruturada, 
              permitindo substituição ou aprimoramento de módulos específicos 
              (por exemplo, trocar o modelo de detecção por outro mais eficiente) 
              sem comprometer o funcionamento geral do sistema.
            </p>
          </div>
        </div>
      </details>

    <!-- ETAPA 3 -->
    <details>
      <summary>ETAPA 3: Seminário S1 do Trabalho</summary>
      <div class="content">
        <div class="refs">
          <a href="imagens/seminários1.pdf" download>Download Seminário S1</a>
        </div>
      </div>
    </details>

    <!-- ETAPA 4 -->
    <details>
      <summary>ETAPA 4: Desenvolvimento do Sistema de Processamento da Visão (SPV)</summary>
      <div class="content">Coloque aqui o conteúdo da Etapa 4.</div>
    </details>

    <!-- ETAPA 5 -->
    <details>
      <summary>ETAPA 5: Desenvolvimento do laboratório experimental (LEx)</summary>
      <div class="content">
        <p>Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier </p>
        <p><strong>Data:</strong> 12/11/2025</p>

        <h3>Objetivo</h3>
        <p>Preparar o Teste de Campo (TC) do SPV por meio do LEx...</p>

        <h3>Roteiro do Laboratório Experimental (para cada aplicação)</h3>
        <ul>
          <li>Roteiro de procedimento experimental...</li>
          <li>Figuras/imagens explicativas...</li>
        </ul>

        <h3>Introdução</h3>
        <p><!-- explicar funcionamento --></p>

        <h3>Procedimento experimental</h3>
        <p><!-- instruções detalhadas --></p>

        <h3>Questionário de avaliação do usuário</h3>
        <ul>
          <li>(i) Entendeu o assunto?</li>
          <li>(ii) Obteve resultados esperados?</li>
          <li>(iii) Entendeu a aplicação?</li>
        </ul>

        <h3>Notas e planilha de médias</h3>
        <ul>
          <li>Atribuir nota por questão; calcular média...</li>
          <li>Enviar a planilha pelo Moodle...</li>
        </ul>

        <h3>Enquete Subjetiva de Opinião (ESO)</h3>
        <ul>
          <li>Perguntas abertas.</li>
          <li>Perguntas com escala 1–5.</li>
        </ul>
      </div>
    </details>

    <!-- ETAPA 6 -->
    <details>
      <summary>ETAPA 6: Teste de Campo do SPV (TC)</summary>
      <div class="content">Coloque aqui o conteúdo da Etapa 6.</div>
    </details>

    <!-- ETAPA 7 -->
    <details>
      <summary>ETAPA 7: Relatório Final do Trabalho (RFT)</summary>
      <div class="content">
        <p>Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier </p>
        <p><strong>Data:</strong> 24/11/2025</p>

        <h3>Introdução</h3>
        <ul>
          <li><strong>Objetivos do trabalho</strong> — <!-- objetivos --></li>
        </ul>

        <h3>Cenário de Aplicação (CA)</h3>
        <p><!-- contexto --></p>

        <h3>Fundamentação teórica</h3>
        <p><!-- teorias e referências --></p>

        <h3>Materiais e métodos</h3>

        <h4>Modelagem Funcional do SPV (MF)</h4>
        <p><!-- diagrama e papéis --></p>

        <h4>Descrição da implementação do SPV</h4>
        <p><!-- algoritmos e pipeline --></p>

        <h4>Lista dos arquivos</h4>
        <ul>
          <li><strong>Códigos-fonte</strong>: <!-- ex.: /src --></li>
          <li><strong>Imagens</strong>: <!-- ex.: /data/images --></li>
          <li><strong>Vídeos</strong>: <!-- ex.: /data/videos --></li>
          <li><strong>Arquivos auxiliares</strong>: <!-- pesos/configs --></li>
        </ul>

        <h4>Análise técnica</h4>
        <ul>
          <li><strong>Métricas objetivas</strong> — precisão, sensibilidade...</li>
          <li><strong>Métricas qualitativas</strong> — usabilidade, feedback...</li>
          <li><strong>Resultados e conclusões parciais</strong> — achados principais...</li>
        </ul>

        <h3>Laboratório Experimental</h3>
        <h4>Roteiro do LEx</h4>
        <p><!-- passos e condições --></p>

        <h4>Análise dos Resultados do TC</h4>
        <ul>
          <li><strong>Experimentos realizados</strong> — ...</li>
          <li><strong>Critérios de avaliação</strong> — ...</li>
          <li><strong>Médias dos alunos</strong> — ...</li>
          <li><strong>Opiniões subjetivas</strong> — ...</li>
        </ul>

        <h3>Conclusões</h3>
        <p><!-- objetivos atingidos; pontos positivos/negativos --></p>

        <h3>Referências Bibliográficas</h3>
        <ul>
          <li><!-- AUTOR. Título. Editora/Conferência, ano. DOI/URL. --></li>
        </ul>

        <h3>Anexo</h3>
        <p><!-- códigos completos/links --></p>
      </div>
    </details>

    <!-- ETAPA 8 -->
    <details>
      <summary>ETAPA 8: Seminário S2 do Trabalho</summary>
      <div class="content">
        <div class="refs">
          <a href="downloads/seminarios2.pdf" download>Download Seminário S2</a>
        </div>
      </div>
    </details>

    <div class="back-top"><a href="#topo" title="Voltar ao topo">↑ Voltar ao topo</a></div>
  </section>

  <!-- =========================
       SEÇÃO: FERNANDA
  ========================== -->
  <section id="fernanda" class="container" aria-labelledby="titulo-fernanda">
    <h2 id="titulo-fernanda" class="section-title">Página da Fernanda</h2>
    <details>
      <summary>Conheça Fernanda</summary>
      <div class="content">
        <p style="text-align:center;">Estudante de Engenharia de Informação da UFABC</p>

        <div style="display:flex; justify-content:center; align-items:center; gap:24px; flex-wrap:wrap; margin-top:16px;">
          <figure style="text-align:center; margin:0;">
            <img src="imagens/Fernanda.png" alt="Foto da Fernanda em sala de aula" style="max-width:250px; height:auto; display:block; margin:0 auto;">
            <figcaption style="margin-top:6px; font-size:14px; color:#000;">Fernanda em sala de aula.</figcaption>
          </figure>

          <figure style="text-align:center; margin:0;">
            <img src="imagens/avatarFernanda.png" alt="Avatar digital em estilo semi-realista da Fernanda" style="max-width:200px; height:auto; display:block; margin:0 auto;">
            <figcaption style="margin-top:6px; font-size:14px; color:#000;">Avatar da Fernanda.</figcaption>
          </figure>
        </div>
      </div>
    </details>
    <div class="back-top"><a href="#topo">↑ Voltar ao topo</a></div>
  </section>

  <!-- =========================
       SEÇÃO: GABRIEL
  ========================== -->
  <section id="gabriel" class="container" aria-labelledby="titulo-gabriel">
    <h2 id="titulo-gabriel" class="section-title">Página do Gabriel</h2>
    <details>
      <summary>Conheça Gabriel</summary>
      <div class="content">
        <p style="text-align:center;">Estudante de Ciência da Computação da UFABC</p>

        <div style="display:flex; justify-content:center; align-items:center; gap:24px; flex-wrap:wrap; margin-top:16px;">
          <figure style="text-align:center; margin:0;">
            <img src="imagens/Gabriel.png" alt="Foto do Gabriel em sala de aula" style="max-width:250px; height:auto; display:block; margin:0 auto;">
            <figcaption style="margin-top:6px; font-size:14px; color:#000;">Gabriel em sala de aula.</figcaption>
          </figure>

          <figure style="text-align:center; margin:0;">
            <img src="imagens/avatarGabriel.png" alt="Avatar digital em estilo semi-realista do Gabriel" style="max-width:200px; height:auto; display:block; margin:0 auto;">
            <figcaption style="margin-top:6px; font-size:14px; color:#000;">Avatar do Gabriel.</figcaption>
          </figure>
        </div>
      </div>
    </details>
    <div class="back-top"><a href="#topo">↑ Voltar ao topo</a></div>
  </section>

  <!-- =========================
       SEÇÃO: INGRID
  ========================== -->
  <section id="ingrid" class="container" aria-labelledby="titulo-ingrid">
    <h2 id="titulo-ingrid" class="section-title">Página da Ingrid</h2>
    <details>
      <summary>Conheça Ingrid</summary>
      <div class="content">
        <p style="text-align:center;">Estudante de Engenharia de Informação da UFABC</p>

        <div style="display:flex; justify-content:center; align-items:center; gap:24px; flex-wrap:wrap; margin-top:16px;">
          <figure style="text-align:center; margin:0;">
            <img src="imagens/Ingrid.png" alt="Foto da Ingrid em sala de aula" style="max-width:250px; height:auto; display:block; margin:0 auto;">
            <figcaption style="margin-top:6px; font-size:14px; color:#000;">Ingrid em sala de aula.</figcaption>
          </figure>

          <figure style="text-align:center; margin:0;">
            <img src="imagens/avatarIngrid.png" alt="Avatar digital em estilo semi-realista da Ingrid" style="max-width:200px; height:auto; display:block; margin:0 auto;">
            <figcaption style="margin-top:6px; font-size:14px; color:#000;">Avatar da Ingrid.</figcaption>
          </figure>
        </div>
      </div>
    </details>
    <div class="back-top"><a href="#topo">↑ Voltar ao topo</a></div>
  </section>


  <!-- =========================
       SEÇÃO: RELATÓRIOS (NOVA)
  ========================== -->
  <section id="relatorios" class="container" aria-labelledby="titulo-relatorios">
    <h2 id="titulo-relatorios" class="section-title">Relatórios</h2>

    <details>
      <summary>Relatório 1</summary>

  <header class="content">
      Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier
      <p><strong>Data:</strong> 06/10/2025</p>
    </div>
  </header>

      <div class="content">
          <h3>1. Introdução</h3>
          <div style="font-family: Arial, sans-serif; line-height: 1.5; text-align: justify;">
          <p> O presente Relatório 1 documenta as atividades iniciais da disciplina ESZI032 – Processamento de Vídeo, cujo objetivo é iniciar o uso do OpenCV, compreender os comandos básicos para visualizar e gravar imagens e vídeos e produzir um primeiro vídeo demonstrativo a ser inserido no relatório. As tarefas foram organizadas em três partes: preparação do ambiente e execução guiada (Parte 1), estudo e adaptação de operações básicas em imagens e vídeos (Parte 2) e obtenção de material próprio com webcam (Parte 3), conforme roteiro do Laboratório 1 – Captura de Imagem e Vídeo (2025.3).</p>
          <p>Na Parte 1, foi configurado o ambiente seguindo as instruções disponibilizadas no Moodle. Na Parte 2, estudamos exemplos de leitura, exibição e gravação de imagens (incluindo a adaptação do tutorial para a imagem messi5.jpg e salvamento em .png) e de leitura/gravação de vídeos (execução dos cinco programas indicados e adaptação para o arquivo big_buck_bunny.mp4), descrevendo a função de cada programa e seu uso em processamento de vídeo. Por fim, na Parte 3, produzimos materiais próprios: uma foto do grupo (com roupas destacando as cores RGB), uma montagem de “avatares” e quatro vídeos de teste (movimentos lentos/rápidos com pessoas e com objeto), que servirão de base para análises futuras e evolução do projeto.</p>

<p>Além de cumprir os objetivos imediatos do laboratório, este relatório busca tornar-se uma referência prática para a equipe RoadWatch sobre a programação de entrada e saída com câmeras, bem como o manuseio de arquivos de imagem e vídeo, estabelecendo um padrão de organização e clareza que será reaproveitado nas próximas etapas.</p>
          </div>

  
  <div class="card">
  <h3>2. Fundamentos Básicos</h3>

  <h4>2.1. Imagem digital e representação em memória</h4>
  <p>Uma imagem digital é uma matriz <em>H × W</em> de pixels com <em>C</em> canais (por exemplo, 3 para imagens coloridas). No OpenCV (C++), a estrutura mais usada é <code>cv::Mat</code>, com valores normalmente inteiros de 8 bits por canal (0–255) em imagens usuais.</p>

  <h4>2.2. Operações básicas em imagens (E/S)</h4>
  <ul>
    <li><strong>Leitura</strong> (entrada): carregar arquivo de imagem com <code>cv::imread()</code>.</li>
    <li><strong>Exibição</strong>: mostrar a imagem com <code>cv::imshow()</code> e aguardar tecla com <code>cv::waitKey()</code>.</li>
    <li><strong>Gravação</strong> (saída): salvar em outro formato com <code>cv::imwrite()</code> (por exemplo, PNG).</li>
  </ul>
  <p>Essas três operações consolidam o fluxo de entrada/saída e permitem conversão simples de formatos.</p>

  <h4>2.3. Vídeo: frames, FPS, resolução, codec e contêiner</h4>
  <ul>
    <li><strong>Frame</strong>: cada imagem individual da sequência do vídeo.</li>
    <li><strong>FPS</strong>: quadros por segundo; influencia a fluidez visual.</li>
    <li><strong>Resolução</strong>: largura × altura; afeta nitidez e tamanho do arquivo.</li>
    <li><strong>Codec/Contêiner</strong>: compressão e empacotamento (ex.: MP4/<code>mp4v</code>).</li>
  </ul>
  <p>Na prática, usamos <code>cv::VideoCapture</code> para leitura e <code>cv::VideoWriter</code> para gravação, ajustando FPS, resolução e codec conforme o objetivo.</p>

  <h4>2.4. Captura com webcam (dispositivos de vídeo)</h4>
  <ol>
    <li>Abrir o dispositivo: <code>cv::VideoCapture(0)</code> (ou outro índice/caminho).</li>
    <li>Ler frames em laço; opcionalmente exibir e/ou gravar.</li>
    <li>Finalizar liberando recursos (fechar janelas e <code>release()</code>).</li>
  </ol>
  <p>Condições como iluminação e velocidade de movimento influenciam nitidez, desfoque e taxa de compressão.</p>

  <h4>2.5. Organização dos exemplos e referencial de estudo</h4>
  <p>Para cada programa executado, descreva o que ele faz, os parâmetros usados (caminhos, FPS, resolução, codec) e como pode ser reutilizado no projeto. Essa documentação vira um guia rápido para as próximas etapas.</p>

  <h4>2.6. Conexão com os objetivos do Lab 1</h4>
  <p>Os conceitos acima (E/S de imagens, leitura/gravação de vídeos e captura com webcam) atendem aos objetivos do Laboratório 1 e servem de base para o desenvolvimento do sistema RoadWatch nas etapas seguintes.</p>
</div>


<div class="card">
  <h3>3. Materiais e Métodos</h3>

  <h4>3.1. Diagrama de Blocos Funcional</h4>
  <figure>
    <img src="imagens/Diagrama de Blocos RoadWatch.png"
         alt="Diagrama de blocos do sistema RoadWatch, com captura pela câmera, pré-processamento, detecção de gestos de uso do celular e emissão de alertas."
         style="max-width:100%;height:auto">
    <figcaption>Fluxo funcional do SPV: Captura → Pré-processamento → Detecção → Alerta/Registro.</figcaption>
  </figure>

  <h4>3.2. Ambiente de Experimentos</h4>
  <ul>
    <li><strong>Sistema Operacional:</strong> Ubuntu 22.04 LTS (64-bit)</li>
    <li><strong>Compilador / Interpretação:</strong> g++ ≥ 11 (C++) ou Python ≥ 3.10</li>
    <li><strong>Bibliotecas:</strong> OpenCV ≥ 4.x (core, imgcodecs, highgui, videoio)</li>
    <li><strong>Hardware:</strong> Webcam USB 720p/1080p; notebook/minipc</li>
    <li><strong>Arquivos de teste (vídeo/imagem):</strong> <code>messi5.jpg</code>, <code>big_buck_bunny.mp4</code></li>
    <li><strong>Ferramentas auxiliares:</strong> Visualizador de imagens, reprodutor de vídeo, terminal</li>
  </ul>

  <h4>3.3. Procedimentos Experimentais</h4>
  <ol>
    <li><strong>Imagem – leitura/exibição/gravação:</strong>
      carregar <code>messi5.jpg</code>, exibir em janela e salvar como <code>saida.png</code> (verificar que o arquivo foi gerado).</li>
    <li><strong>Vídeo – leitura:</strong> abrir <code>big_buck_bunny.mp4</code> com <code>VideoCapture</code>, ler frames em laço e exibir.</li>
    <li><strong>Vídeo – gravação:</strong> gravar um trecho para <code>saida.mp4</code> definindo resolução e FPS (ex.: 640×480 @ 30fps).</li>
    <li><strong>Webcam – captura de foto:</strong> capturar uma imagem do grupo e salvar como <code>foto_grupo.png</code>
      (roupas com cores RGB destacadas).</li>
    <li><strong>Webcam – “avatares”:</strong> montar uma imagem com retratos (avatars) dos integrantes e salvar como <code>avatares.png</code>.</li>
    <li><strong>Webcam – vídeos próprios:</strong> gravar 4 vídeos curtos:
      <ul>
        <li>Pessoa com movimento <em>lento</em> e <em>rápido</em></li>
        <li>Objeto com movimento <em>lento</em> e <em>rápido</em></li>
      </ul>
      Nomear como <code>pessoa_lento.mp4</code>, <code>pessoa_rapido.mp4</code>, <code>objeto_lento.mp4</code>, <code>objeto_rapido.mp4</code>.
    </li>
    <li><strong>Anotações no relatório:</strong> descrever o que cada programa faz, parâmetros usados (FPS, resolução, codec) e observações sobre iluminação, nitidez, desfoque e compressão.</li>
  </ol>

  <h4>3.4. Organização de Arquivos</h4>
  <pre><code>projeto/
├─ imagens/
│  ├─ messi5.jpg
│  ├─ saida.png
│  └─ avatares.png
├─ videos/
│  ├─ big_buck_bunny.mp4
│  ├─ saida.mp4
│  ├─ pessoa_lento.mp4
│  ├─ pessoa_rapido.mp4
│  ├─ objeto_lento.mp4
│  └─ objeto_rapido.mp4
└─ src/
   ├─ img_io.cpp        # leitura/exibição/gravação de imagem
   ├─ video_read.cpp    # leitura de vídeo
   ├─ video_write.cpp   # gravação de vídeo
   └─ webcam_cap.cpp    # captura da webcam
</code></pre>

  <h4>3.5. Parâmetros e Configuração Utilizada</h4>
  <ul>
    <li><strong>Resoluções:</strong> 640×480 e 1280×720</li>
    <li><strong>FPS:</strong> 24 e 30 (comparar fluidez)</li>
    <li><strong>Codec:</strong> <code>mp4v</code> (MP4) para arquivos de saída</li>
    <li><strong>Iluminação:</strong> ambiente interno com luz frontal difusa; repetir com luz lateral</li>
    <li><strong>Duração dos vídeos:</strong> 5–10 s (cada)</li>
  </ul>

  <h4>3.6. Critérios de Validação e Registro</h4>
  <ul>
    <li>Verificar se a <strong>resolução e FPS</strong> do arquivo de saída batem com o solicitado.</li>
    <li>Registrar <strong>observações</strong> de nitidez, ruído, desfoque por movimento e variações de iluminação.</li>
    <li>Inserir no relatório <strong>figuras</strong> (frames representativos) com <strong>legenda acessível</strong> e breve análise.</li>
    <li>Guardar <strong>prints de terminal</strong> com logs de execução e mensagens de erro (se houver).</li>
  </ul>

        <div class="card">
          <h3>4. Resultados e Análises</h3>
          <h4>(A) Leitura de imagem em arquivo e exibir na tela:</h4>
          <p style="text-align: justify;"> As imagens apresentadas correspondem à execução prática do tutorial “Getting Started with Images” da biblioteca OpenCV, utilizando a imagem messi5.jpg. O objetivo é demonstrar a leitura de uma imagem a partir de um arquivo e sua exibição em uma janela na tela.</p>
      
          <p><strong>Primeira imagem — Execução pela linha de comando (C++)</strong></p>
       <p style="text-align: justify;">Vê-se a janela do programa DisplayImage, aberta com o título “Display Image”.
Dentro dessa janela, aparece uma fotografia colorida do jogador de futebol Lionel Messi. A figura demonstra o funcionamento correto do programa em C++ para leitura e exibição de imagens, conforme o tutorial da documentação do OpenCV. A execução confirma que o código foi compilado e executado com sucesso, exibindo a imagem carregada.</p>
          <div style="text-align: center; font-family: Arial, sans-serif;">
  <figure>
    <img src="imagens/captura_displayimage.png" 
         alt="Captura de tela no Linux mostrando a execução do programa DisplayImage no terminal. Uma janela chamada 'Display Image' exibe uma foto de um jogador de futebol em uniforme azul e grená do Barcelona, realizando um movimento com a bola em campo." 
         style="max-width: 90%; height: auto; border: 1px solid #ccc; border-radius: 8px;">
    <figcaption style="margin-top: 8px; font-size: 14px; color: ##000000;">
      Captura de tela do programa <b>DisplayImage</b> em execução no terminal Linux, 
      exibindo uma janela com a imagem de um jogador de futebol em campo. 
      Esse resultado demonstra o correto funcionamento do código para abertura de imagens.
    </figcaption>
  </figure>
</div>

<p><strong>Segunda imagem — Execução em Python</strong></p>
<p style="text-align: justify;">Abre-se uma janela intitulada “image”, exibindo a mesma fotografia de Messi, agora processada via script Python utilizando as funções cv2.imread() e cv2.imshow().O resultado visual confirma que o código em Python reproduz o mesmo comportamento do programa em C++, realizando corretamente a leitura e exibição da imagem messi5.jpg.</p>
  <div style="text-align: center; font-family: Arial, sans-serif;">
  <figure>
    <img src="imagens/py.png" 
         alt="Captura de tela no Linux mostrando a execução do programa DisplayImage no terminal. Uma janela chamada 'Display Image' exibe uma foto de um jogador de futebol em uniforme azul e grená do Barcelona, realizando um movimento com a bola em campo." 
         style="max-width: 90%; height: auto; border: 1px solid #ccc; border-radius: 8px;">
    <figcaption style="margin-top: 8px; font-size: 14px; color: ##000000;">
      Configurando o Python
    </figcaption>
  </figure>
</div>

  <h4> (B) Leitura e gravação de vídeo: </h4>
  <h4 style="text-align:left; margin: 16px 32px;"> 1) video_read_from_files</h4>
  <p style="margin: 16px 32px; text-align: justify;"> 
    O programa utiliza a biblioteca OpenCV para abrir, ler e exibir um vídeo a partir de um arquivo, mostrando cada frame em uma nova janela e permitindo que o usuário interrompa a reprodução pressionando a tecla 'q'. 
  </p>
      <figure style="text-align:center; margin:16px auto;">
  <img src="imagens/Captura de tela de 2025-10-01 11-38-24.png" 
       alt="Descrição acessível da imagem exibida" 
       style="max-width:60%; height:auto; border:1px solid #ccc; border-radius:8px;">
  <figcaption style="margin-top:8px; font-size:14px; color:#00000;">
    Frame do vídeo "Cars.mp4", mostrando a captura em tempo real após a execução do programa.
  </figcaption>

<h4 style="text-align:left; margin: 16px 32px;">2) video_read_from_image_sequence</h4>
<p style="margin: 16px 32px; text-align: justify;">
  O programa lê uma sequência de imagens numeradas e as exibe em sequência como se fossem um vídeo, utilizando a biblioteca OpenCV.
</p>
      <figure style="text-align:center; margin:16px auto;">
  <img src="imagens/Captura de tela de 2025-10-01 11-53-22.png" 
       alt="Descrição acessível da imagem exibida" 
       style="max-width:60%; height:auto; border:1px solid #ccc; border-radius:8px;">
  <figcaption style="margin-top:8px; font-size:14px; color:#00000;">
    A imagem exibe um frame da sequência de imagens enumeradas.
  </figcaption>

<h4 style="text-align:left; margin: 16px 32px;"> 3) video_read_from_webcam</h4>
<p style="margin: 16px 32px; text-align: justify;"> 
  O programa captura vídeo em tempo real a partir da webcam do computador, exibindo os quadros em uma nova janela.
</p>
      <figure style="text-align:center; margin:16px auto;">
  <img src="imagens/Captura de tela de 2025-10-01 11-44-32.png" 
       alt="Descrição acessível da imagem exibida" 
       style="max-width:60%; height:auto; border:1px solid #ccc; border-radius:8px;">
  <figcaption style="margin-top:8px; font-size:14px; color:#00000;">
    Captura de tela a partir da webcam do computador.
  </figcaption>

<h4 style="text-align:left; margin: 16px 32px;"> 4) video_write_from_webcam</h4>
<p style="margin: 16px 32px; text-align: justify;">
  O programa captura um vídeo em tempo real a partir da webcam do computador, exibindo os quadros em uma nova janela e simultaneamente salvando o vídeo em um novo arquivo.
</p>
      <figure style="text-align:center; margin:16px auto;">
  <div style="position:relative; max-width:60%; margin:12px auto; aspect-ratio:16/9;">
    <video id="vid1"
           controls
           preload="metadata"
           playsinline
           style="width:100%; height:100%; display:block; border:1px solid #ddd; border-radius:10px;">
      <source src="imagens/Gravação de Tela 2025-10-04 145536.mp4" type="video/mp4">
      Seu navegador não suporta o elemento <code>video</code>.
    </video>
  </div>
  <figcaption style="margin-top:8px; font-size:14px; color:#00000;">
    Captura de vídeo em tempo real a partir da webcam do computador.
  </figcaption>

<h4 style="text-align:left; margin: 16px 32px;"> 5) video_write_to_file</h4>
<p style="margin: 16px 32px; text-align: justify;">
  O programa lê um vídeo pré-existente, exibe os quadros em tempo real em uma nova janela e simultaneamente grava o conteúdo em um novo arquivo de vídeo.
</p>
      <figure style="text-align:center; margin:16px auto;">
  <img src="imagens/Captura de tela de 2025-10-01 11-45-32.png" 
       alt="Descrição acessível da imagem exibida" 
       style="max-width:60%; height:auto; border:1px solid #ccc; border-radius:8px;">
  <figcaption style="margin-top:8px; font-size:14px; color:#00000;">
    A imagem exibe um frame do vídeo "Cars.mp4", acionado após a execução do programa.
  </figcaption>

        
      <h4 style="text-align:left;"> Obtenção de Fotos e Vídeos</h4>
      <h4 style="text-align:left;"> a) </h4>
      <figure style="text-align:center; margin:16px auto;">
  <img src="imagens/equipe.png" 
       alt="Descrição acessível da imagem exibida" 
       style="max-width:90%; height:auto; border:1px solid #ccc; border-radius:8px;">
  <figcaption style="margin-top:8px; font-size:14px; color:#00000;">
    Foto de todos integrantes do grupo obtida via webcam.
  </figcaption>
</figure>

  <h4 style="text-align:left;"> b) </h4>
      <figure style="text-align:center; margin:16px auto;">
  <img src="imagens/avatares_juntos.png"
       alt="Descrição acessível da imagem exibida" 
       style="max-width:70%; height:auto; border:1px solid #ccc; border-radius:8px;">
  <figcaption style="margin-top:8px; font-size:14px; color:#00000;">
    Avatares dos integrantes do grupo.
  </figcaption>
</figure>

 <h4 style="text-align:left;"> c) Vídeo com a webcam com pessoas e com um objeto:</h4>
    <figure style="text-align:center">
  <div style="position:relative; max-width:900px; margin:12px auto; aspect-ratio:16/9;">
    <video id="vid1"
           controls
           preload="metadata"
           playsinline
           style="width:100%; height:100%; display:block; border:1px solid #ddd; border-radius:10px;">
      <source src="imagens/Grava%C3%A7%C3%A3o%20de%20tela%20de%202025-10-01%2011-34-00.webm" type="video/webm">
      Seu navegador não suporta o elemento <code>video</code>.
    </video>
  </div>
  <figcaption>Leitura e gravação de vídeo com mudanças lentas de movimento  — reprodução local.</figcaption>

  <!-- teste: abrir o arquivo direto -->
  <p style="margin-top:8px">
    <a href="imagens/Grava%C3%A7%C3%A3o%20de%20tela%20de%202025-10-01%2011-34-00.webm" target="_blank" rel="noopener">
      Abrir arquivo WEBM diretamente
    </a>
  </p>
</figure>

    <figure style="text-align:center">
  <div style="position:relative; max-width:900px; margin:12px auto; aspect-ratio:16/9;">
    <video id="vid1"
           controls
           preload="metadata"
           playsinline
           style="width:100%; height:100%; display:block; border:1px solid #ddd; border-radius:10px;">
      <source src="imagens/Gravação de tela de 2025-10-01 11-35-37.webm " type="video/webm">
      Seu navegador não suporta o elemento <code>video</code>.
    </video>
  </div>
  <figcaption>Leitura e gravação de vídeo com mudanças rápidas de movimento — reprodução local.</figcaption>

  <!-- teste: abrir o arquivo direto -->
  <p style="margin-top:8px">
    <a href="imagens/Grava%C3%A7%C3%A3o%20de%20tela%20de%202025-10-01%2011-35-37.webm" target="_blank" rel="noopener">
      Abrir arquivo WEBM diretamente
    </a>
  </p>
</figure>


      <div class="card">
        <h3 style="text-align:left;">5. Conclusões</h3>
        	<p style="font-family: Arial, sans-serif; line-height: 1.5; text-align: justify; margin: 16px 32px;">
             O Laboratório 1 permitiu que o grupo se familiarizasse com o uso do OpenCV, 
          	 consolidando conhecimentos sobre leitura, exibição e gravação de imagens e vídeos, 
          	 além da prática de captura com webcam. As atividades reforçaram o entendimento de conceitos como 
             resolução, representação de frames e formatos de arquivo, bem como a importância de fatores 
             externos como iluminação e velocidade de movimento na qualidade do material obtido.
        	</p>
        	<p style="font-family: Arial, sans-serif; line-height: 1.5; text-align: justify; margin: 16px 32px;">
             Entre as principais dificuldades observadas estão a necessidade de ajustes finos de parâmetros 
             para garantir nitidez e fluidez nos vídeos, além dos efeitos causados por variações de iluminação, 
        	   que influenciam diretamente a qualidade da captura. Tais desafios, entretanto, contribuíram para a 
        	   compreensão prática do impacto desses fatores em aplicações de visão computacional.
        	</p>
  	      <p style="font-family: Arial, sans-serif; line-height: 1.5; text-align: justify; margin: 16px 32px;">
             Como próximo passo, este relatório servirá como referência para as etapas seguintes da disciplina 
             e para o desenvolvimento do sistema RoadWatch, um programa que, por meio de uma câmera, 
             será capaz de identificar se o motorista está utilizando o celular durante a condução. 
             Além de guiar a organização de arquivos, a padronização de experimentos e a documentação dos resultados, 
             esta base inicial estabelece condições sólidas para avançar no nosso projeto final.
  	      </p>
        </div>
      </div>
    </details>
  </div>
    
      <!-- RELATÓRIO 2 -->
  <details>
    <summary>Relatório 2</summary>
    <header class="content">
      <p><strong>Integrantes:</strong> Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier</p>
      <p><strong>Data:</strong> 15/10/2025</p>
    </header>
    <div class="content">
      <h3>1. Introdução</h3>
      <p style="text-align:justify;">Esta parte do trabalho investiga, de forma sistemática, o efeito de diferentes filtros espaciais e tamanhos de máscara na qualidade de imagens estáticas e em vídeo. Partimos do conjunto de imagens próprias obtidas no Lab 1 e aplicamos quatro técnicas clássicas de suavização: média, gaussiano, mediana e bilateral. Para cada filtro, variamos o tamanho do kernel (3×3, 5×5, 7×7 e 11×11) e salvamos os resultados em formato `.jpg`, de modo a permitir comparações diretas entre combinações de método e escala. O objetivo é compreender o compromisso entre redução de ruído e preservação de detalhes (bordas e texturas), bem como o impacto da granularidade da vizinhança na suavização.</p>

<p style="text-align:justify;">Na sequência, repetimos os experimentos sob uma condição mais adversa: a adição de ruído sal-e-pimenta à imagem original. Esse cenário é particularmente útil para destacar diferenças entre filtros que operam por média/ponderação (média e gaussiano), filtros não lineares robustos a impulsos (mediana) e o filtro bilateral, que combina proximidade espacial e similaridade radiométrica para preservar bordas. A análise contempla tanto a variação do kernel dentro de cada filtro quanto a comparação entre filtros para um mesmo kernel.</p>

<p style="text-align:justify;">Por fim, avaliamos o comportamento em tempo real com entrada de webcam, mostrando continuamente a imagem filtrada em uma janela do OpenCV e permitindo capturas (`.jpg`) via teclado. As escolhas dos dois filtros e kernels usados nesta etapa derivam dos melhores e piores desempenhos observados no cenário com ruído, consolidando a discussão com um caso prático. Opcionalmente, propomos ainda uma extensão interativa que habilita a seleção dinâmica do tipo de filtragem e do tamanho da máscara pelo usuário. Para reprodutibilidade e organização, cada programa é mantido em pastas distintas, com saídas nomeadas de forma consistente.
</p>
      <h3>2. Fundamentos Básicos</h3>
  <p><strong>Objetivo:</strong> reduzir variações de alta frequência (ruído/detalhes finos) preservando estruturas relevantes (bordas e texturas). É etapa comum de pré-processamento para segmentação, detecção de bordas e descrição de regiões.</p>

  <h3>1) Modelo de ruído</h3>
  <p>Imagem observada: <code>g(x,y) = f(x,y) + n(x,y)</code>, onde <em>f</em> é a imagem ideal e <em>n</em> o ruído (gaussiano, sal-e-pimenta etc.). A filtragem busca aproximar <em>f</em> atenuando <em>n</em>.</p>

  <h3>2) Filtragem espacial e convolução</h3>
  <p>Filtros aplicam uma máscara (<em>kernel</em>) sobre vizinhanças. Em filtros lineares:</p>
  <p style="margin:8px 0"><code>I'(x,y) = Σ Σ K(i,j) · I(x+i, y+j)</code></p>
  <p>É necessário definir tratamento de borda (<code>padding</code>: replicar, refletir, constante).</p>

  <h3>3) Tamanho do kernel (3×3, 5×5, 7×7, 11×11)</h3>
  <ul>
    <li><strong>Maior kernel</strong>: remove mais ruído, porém aumenta borramento e custo computacional.</li>
    <li><strong>Menor kernel</strong>: preserva detalhes/bordas, remove menos ruído.</li>
  </ul>

  <h3>4) Tipos de filtro</h3>
  <ul>
    <li><strong>Média (box blur) — linear:</strong> substitui pelo valor médio da vizinhança. Simples e rápido; tende a borrar bordas.</li>
    <li><strong>Gaussiano — linear:</strong> pesos conforme distribuição normal (maior peso no centro). Melhor que a média para preservar bordas; parâmetro-chave: <em>σ</em>.</li>
    <li><strong>Mediana — não linear:</strong> substitui pelo valor mediano. Excelente para <em>sal-e-pimenta</em>; preserva bordas finas; pode “achatar” texturas.</li>
    <li><strong>Bilateral — não linear (espaço + intensidade):</strong> suaviza regiões mantendo bordas ao reduzir peso quando a diferença de intensidade é grande. Qualidade alta, custo computacional maior; sensível a <code>d</code>, <code>sigmaColor</code>, <code>sigmaSpace</code>.</li>
  </ul>

  <h3>5) Ruído sal-e-pimenta</h3>
  <ul>
    <li><strong>Mediana</strong> costuma ser a melhor escolha (remove impulsos sem espalhá-los).</li>
    <li><strong>Média/Gaussiano</strong> reduzem mas podem espalhar impulsos (halos).</li>
    <li><strong>Bilateral</strong> pode funcionar bem, porém exige ajuste fino e é mais lento.</li>
  </ul>

  <h3>6) Métricas para análise</h3>
  <ul>
    <li><strong>Avaliação visual</strong> de borramento e preservação de bordas.</li>
    <li><strong>Histograma</strong> (estreitamento indica suavização).</li>
    <li><strong>PSNR/SSIM</strong> quando houver referência limpa (opcional).</li>
    <li><strong>Tempo de execução</strong> (cresce com o kernel; bilateral é o mais caro).</li>
  </ul>

  <h3>7) Boas práticas (OpenCV)</h3>
  <ul>
    <li>Para RGB, filtrar por canal ou converter para tons de cinza para análise.</li>
    <li>Escolher borda adequada (<code>BORDER_REFLECT</code> geralmente é bom padrão).</li>
    <li>Registrar parâmetros (tipo de filtro + kernel + σ) e salvar resultados por pasta (exigência do lab).</li>
  </ul>

  <h3>8) Expectativa ao variar o kernel</h3>
  <ul>
    <li><strong>3×3</strong>: leve redução de ruído; detalhes preservados.</li>
    <li><strong>5×5 / 7×7</strong>: bom compromisso entre limpeza e nitidez.</li>
    <li><strong>11×11</strong>: forte suavização; útil para ruído pesado, com perda de texturas.</li>
  </ul>


      <h3>3. Materiais e Métodos</h3>
      <p style="text-align:justify;">Os experimentos foram realizados utilizando a linguagem de programação C++ e a biblioteca OpenCV 4.x, em ambiente Linux (Ubuntu), com o compilador g++ e editor de código Visual Studio Code. Foram empregadas funções nativas do OpenCV para leitura, exibição e gravação de imagens, tais como `imread()`, `imshow()` e `imwrite()`, além das funções de filtragem `blur()`, `GaussianBlur()`, `medianBlur()` e `bilateralFilter()`. Para a parte prática envolvendo captura de vídeo, utilizou-se também a função `VideoCapture()` para acesso à webcam do computador. A imagem original utilizada como base foi a obtida no Laboratório 1, sendo processada e salva em formato .jpg em diferentes etapas.</p>

<p style="text-align:justify;">Inicialmente, desenvolveu-se um programa para aplicar quatro tipos de filtros espaciais — média, gaussiano, mediana e bilateral — sobre a imagem original, utilizando um kernel de tamanho 3×3. O procedimento foi repetido com os tamanhos de kernel 5×5, 7×7 e 11×11, de modo a avaliar a influência do aumento da vizinhança na suavização da imagem. Cada imagem resultante foi armazenada em pastas distintas, nomeadas de acordo com o filtro e o tamanho do kernel utilizado. Em seguida, os resultados foram analisados visualmente para verificar o efeito do aumento do kernel sobre a nitidez e a preservação das bordas, bem como a diferença de desempenho entre os tipos de filtros aplicados.</p>

<p style="text-align:justify;">Na segunda etapa, adicionou-se ruído do tipo sal-e-pimenta à imagem original e repetiram-se as filtragens. O objetivo foi comparar a eficiência de cada filtro na remoção desse tipo de ruído impulsivo, observando a suavização e a preservação das bordas. Posteriormente, foi desenvolvido um novo programa para processar imagens capturadas em tempo real pela webcam, permitindo aplicar dois dos filtros estudados — selecionados com base nos melhores e piores resultados das etapas anteriores. A exibição dos resultados foi feita em uma janela do OpenCV, com a possibilidade de salvar a imagem corrente ao pressionar a tecla “s”.</p>

<p style="text-align:justify;">Por fim, foi elaborado um programa adicional (desafio opcional) que permite ao usuário selecionar o tipo de filtro e o tamanho do kernel por meio do teclado, durante a execução da captura da webcam. As teclas [a], [g], [m] e [b] foram associadas aos filtros de média, gaussiano, mediana e bilateral, respectivamente, enquanto as teclas [3], [5], [7], [9] e [11] definiram os tamanhos de kernel correspondentes. O sistema exibia em tempo real o resultado da filtragem conforme as seleções do usuário. Todo o conjunto de imagens processadas foi salvo de forma organizada em subpastas nomeadas conforme o tipo de filtro e o kernel utilizados, permitindo uma análise sistemática dos efeitos de cada variação.
</p>

<p><strong>Diagrama de bloco</strong></p>
<figure style="max-width: 720px; margin: 16px auto; text-align: center;">
  <img src="imagens/diagrama_bloco2.png"
       alt="Diagrama de blocos do experimento de filtragem e suavização de imagens com decisões if, sim e não."
       loading="lazy"
       style="width:60%; height:auto; border-radius:8px; border:1px solid #ccc;">
  <figcaption style="font:14px/1.4 Arial, sans-serif; color:#00000; margin-top:8px;">
    Diagrama de Blocos — Filtragem e Suavização de Imagens (OpenCV).
  </figcaption>
</figure>
  
      <h3>4. Resultados e Análises</h3>
      <p><strong>1)</strong> Nesta parte, usamos nossas próprias imagens obtidas no Lab1.</p> 

   <p style="text-align:justify;">Elaboramos um programa que realize as filtragens (com os filtros de média, gaussiano, mediana, e bilateral) na sua imagem com um kernel 3x3, e salvamos as imagens resultantes de cada filtragem, em formato .jpg.  Repita todas filtragens, elaborando novos programas com kernel 5x5, 7x7, e 11x11, salvando a imagem resultante de cada kernel. </p>

<!DOCTYPE html>
<html lang="pt-BR">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>Filtragens — Resultados do Lab 1</title>
<style>
  body {
    background-color: #eebbbb;
    color: #222;
    font-family: Arial, Helvetica, sans-serif;
    margin: 0;
    padding: 16px;
  }
  p {
    text-align: justify;
    margin: 16px auto;
    max-width: 900px;
  }
  figure {
    max-width: 720px;
    margin: 20px auto;
    text-align: center;
  }
  figure img {
    width: 60%;
    height: auto;
    border-radius: 8px;
    border: 1px solid #ccc;
    display: block;
    margin: 0 auto;
  }
  figcaption {
    font: 14px/1.4 Arial, sans-serif;
    color: #000;
    margin-top: 8px;
  }
</style>
</head>
<body>

<p>Elaboramos um programa que realize as filtragens (com os filtros de média, gaussiano, mediana e bilateral) na sua imagem com um kernel 3x3, e salvamos as imagens resultantes de cada filtragem, em formato .jpg. Repetimos todas filtragens, elaborando novos programas com kernel 5x5, 7x7 e 11x11, salvando a imagem resultante de cada kernel.</p>

<figure>
  <img src="imagens/foto_grupo.jpg" alt="Foto em grupo original do Lab 1.">
  <figcaption>Foto em grupo original do Lab 1.</figcaption>
</figure>

<figure>
  <img src="imagens/saida_bilateral_3x3.jpg" alt="Saída Bilateral 3x3.">
  <figcaption>Saída Bilateral 3×3</figcaption>
</figure>

<figure>
  <img src="imagens/saida_bilateral_5x5.jpg" alt="Saída Bilateral 5x5.">
  <figcaption>Saída Bilateral 5×5</figcaption>
</figure>

<figure>
  <img src="imagens/saida_bilateral_7x7.jpg" alt="Saída Bilateral 7x7.">
  <figcaption>Saída Bilateral 7×7</figcaption>
</figure>

<figure>
  <img src="imagens/saida_bilateral_11x11.jpg" alt="Saída Bilateral 11x11.">
  <figcaption>Saída Bilateral 11×11</figcaption>
</figure>

<figure>
  <img src="imagens/saida_gaussiana_3x3.jpg" alt="Saída Gaussiana 3x3.">
  <figcaption>Saída Gaussiana 3×3</figcaption>
</figure>

<figure>
  <img src="imagens/saida_gaussiana_5x5.jpg" alt="Saída Gaussiana 5x5.">
  <figcaption>Saída Gaussiana 5×5</figcaption>
</figure>

<figure>
  <img src="imagens/saida_gaussiana_7x7.jpg" alt="Saída Gaussiana 7x7.">
  <figcaption>Saída Gaussiana 7×7</figcaption>
</figure>

<figure>
  <img src="imagens/saida_gaussiana_11x11.jpg" alt="Saída Gaussiana 11x11.">
  <figcaption>Saída Gaussiana 11×11</figcaption>
</figure>

<figure>
  <img src="imagens/saida_media_3x3.jpg" alt="Saída Média 3x3.">
  <figcaption>Saída Média 3×3</figcaption>
</figure>

<figure>
  <img src="imagens/saida_media_5x5.jpg" alt="Saída Média 5x5.">
  <figcaption>Saída Média 5×5</figcaption>
</figure>

<figure>
  <img src="imagens/saida_media_7x7.jpg" alt="Saída Média 7x7.">
  <figcaption>Saída Média 7×7</figcaption>
</figure>

<figure>
  <img src="imagens/saida_media_11x11.jpg" alt="Saída Média 11x11.">
  <figcaption>Saída Média 11×11</figcaption>
</figure>

<figure>
  <img src="imagens/saida_mediana_3x3.jpg" alt="Saída Mediana 3x3.">
  <figcaption>Saída Mediana 3×3</figcaption>
</figure>

<figure>
  <img src="imagens/saida_mediana_5x5.jpg" alt="Saída Mediana 5x5.">
  <figcaption>Saída Mediana 5×5</figcaption>
</figure>

<figure>
  <img src="imagens/saida_mediana_7x7.jpg" alt="Saída Mediana 7x7.">
  <figcaption>Saída Mediana 7×7</figcaption>
</figure>

<figure>
  <img src="imagens/saida_mediana_11x11.jpg" alt="Saída Mediana 11x11.">
  <figcaption>Saída Mediana 11×11</figcaption>
</figure>

</body>
</html>

<p><strong>2)</strong> Repetimos o procedimento acima, adicionando o ruído tipo sal-e-pimenta na imagem original. </p>

<figure>
  <img src="imagens/original.png" 
  <figcaption>Imagem Sal e Pimenta original.</figcaption>
</figure>

<figure>
  <img src="imagens/saida_bilateral_3x3_noise.jpg" 
  <figcaption>Saída Bilateral 3x3.</figcaption>
</figure>
    
<figure>
  <img src="imagens/saida_bilateral_5x5_noise.jpg" 
  <figcaption>Saída Bilateral 5x5.</figcaption>
</figure>    
   
<figure>
  <img src="imagens/saida_bilateral_7x7_noise.jpg" 
  <figcaption>Saída Bilateral 7x7.</figcaption>
</figure>      

<figure>
  <img src="imagens/saida_bilateral_11x11_noise.jpg" 
  <figcaption>Saída Bilateral 11x11.</figcaption>
</figure>  

<figure>
  <img src="imagens/saida_gaussiana_3x3_noise.jpg" 
  <figcaption>Saída Gaussiana 3x3.</figcaption>
</figure>       
      
<figure>
  <img src="imagens/saida_gaussiana_5x5_noise.jpg" 
  <figcaption>Saída Gaussiana 5x5.</figcaption>
</figure>       
           
<figure>
  <img src="imagens/saida_gaussiana_7x7_noise.jpg" 
  <figcaption>Saída Gaussiana 7x7.</figcaption>
</figure>       

<figure>
  <img src="imagens/saida_gaussiana_11x11_noise.jpg" 
  <figcaption>Saída Gaussiana 11x11.</figcaption>
</figure>  
      
     
<figure>
  <img src="imagens/saida_media_3x3_noise.jpg" 
  <figcaption>Saída Média 3x3.</figcaption>
</figure>       
      
<figure>
  <img src="imagens/saida_media_5x5_noise.jpg" 
  <figcaption>Saída Média 5x5.</figcaption>
</figure>       

<figure>
  <img src="imagens/saida_media_7x7_noise.jpg" 
  <figcaption>Saída Média 7x7.</figcaption>
</figure>       

<figure>
  <img src="imagens/saida_media_11x11_noise.jpg" 
  <figcaption>Saída Média 11x11.</figcaption>
</figure>       
     
<figure>
  <img src="imagens/saida_mediana_3x3_noise.jpg" 
  <figcaption>Saída Mediana 3x3.</figcaption>
</figure>       

<figure>
  <img src="imagens/saida_mediana_5x5_noise.jpg" 
  <figcaption>Saída Mediana 5x5.</figcaption>
</figure>       
      
 <figure>
  <img src="imagens/saida_mediana_7x7_noise.jpg" 
  <figcaption>Saída Mediana 7x7.</figcaption>
  
  
  <figure>
  <img src="imagens/saida_mediana_11x11_noise.jpg" 
  <figcaption>Saída Mediana 11x11.</figcaption>
</figure>       
  
  <figure>
  <img src="imagens/imagem_ruido_salpimenta.jpg" 
  <figcaption>Saída com ruído.</figcaption>
</figure> 

  <p>Foram aplicados quatro tipos de filtragem (<strong>Gaussiano</strong>, <strong>Bilateral</strong>, <strong>Média</strong> e <strong>Mediana</strong>) sobre a mesma imagem original, utilizando tamanhos de kernel 3×3, 5×5, 7×7 e 11×11.  
  A seguir são descritos os efeitos observados visualmente em cada caso.</p>

  <h3>1. Filtro Gaussiano</h3>
  <div class="resumo">
    <p><strong>3×3:</strong> leve suavização; contornos permanecem bem definidos.<br>
    <strong>5×5:</strong> suavização perceptível, pequenas áreas de ruído desaparecem.<br>
    <strong>7×7:</strong> textura mais aveludada; perda de detalhes finos.<br>
    <strong>11×11:</strong> borramento forte e perda de nitidez geral.</p>
  </div>

  <h3>2. Filtro Bilateral</h3>
  <div class="resumo">
    <p><strong>3×3:</strong> suavização leve, sem perda de contornos.<br>
    <strong>5×5:</strong> aspecto limpo e suave, bordas ainda bem definidas.<br>
    <strong>7×7:</strong> aparência de “pele filtrada”, contraste natural.<br>
    <strong>11×11:</strong> efeito de pintura digital; superfícies uniformes e contornos bem preservados.</p>
  </div>

  <h3>3. Filtro de Média</h3>
  <div class="resumo">
    <p><strong>3×3:</strong> leve borramento; ruídos pequenos desaparecem.<br>
    <strong>5×5:</strong> perda de nitidez moderada; bordas suavizadas.<br>
    <strong>7×7:</strong> imagem mais desfocada, texturas diluídas.<br>
    <strong>11×11:</strong> borramento intenso; aparência de embaçado geral.</p>
  </div>

  <h3>4. Filtro Mediana</h3>
  <div class="resumo">
    <p><strong>3×3:</strong> remove ruídos leves sem alterar contornos.<br>
    <strong>5×5:</strong> ruídos isolados totalmente removidos.<br>
    <strong>7×7:</strong> superfícies mais uniformes; pequenas bordas suavizadas.<br>
    <strong>11×11:</strong> possível distorção em detalhes finos, porém excelente redução de ruído.</p>


    <p style="text-align:justify;"> Logo, o filtro bilateral apresenta o melhor equilíbrio entre suavização e preservação de detalhes, enquanto o filtro de média é o que mais degrada a nitidez. O filtro mediana se destaca em imagens com ruído tipo sal-e-pimenta, e o Gaussiano oferece suavização homogênea com bom controle visual.</p>

  </main>
  </body>
  </html>
    
<p> <strong> 3) </strong> Elabore um novo programa em que a imagem de entrada é da webcam, e que mostre o resultado da filtragem numa janela opencv, de forma contínua na tela do computar. Utilize a tecla [s] do teclado para permitir salvar a imagem sendo apresentada na tela, em formato .jpg. Neste caso, escolha apenas  dois tipos de filtragem e tamanho de kernel, baseado no melhor e no pior resultado obtidos na parte (2) acima.</p>    


 
<figure>
  <div class="video-container">
    <video controls style="width:70%; max-width:900px; height:auto; border-radius:10px;">
      <source src="imagens/Gravação de tela de 2025-10-08 10-38-21.webm" type="video/webm">
      Seu navegador não suporta a reprodução de vídeo.
    </video>
  </div>
  <figcaption>
    Gravação de tela mostrando a execução do programa de filtragem.<kbd>s</kbd>.
  </figcaption>
</figure>   
</body>
</html>
       
  <figure>
  <img src="imagens/frame_melhor_20251008_103834.jpg" 
  <figcaption>Tela com melhor frame.</figcaption>
</figure>     

  <figure>
  <img src="imagens/frame_pior_20251008_103512.jpg" 
  <figcaption>Tela com pior frame.</figcaption>
</figure>     

  <h3>Arquivo C++ </h3>


  <div class="frame-wrap">
  
  <iframe src="imagens/video_read_from_webcam.cpp"  style="width:80%;height:500px;border:2px solid #751a32;border-radius:10px;background:#fff;resize:both;overflow:auto;display:block;margin:20px auto;"></iframe>
</div>

<div class="download">
  <a href="imagens/video_read_from_webcam.cpp" download> Baixar código</a>
</div>

</body>
</html>
    
      <h3>5. Conclusões</h3>
      <p style="text-align:justify;">A partir dos experimentos, verificou-se que o tamanho do kernel é determinante no compromisso entre suavização e nitidez: kernels maiores (7×7 e 11×11) intensificam a redução de ruído, porém degradam detalhes e bordas; kernels menores (3×3 e 5×5) preservam melhor as texturas e contornos, com suavização mais discreta.</p>

<p style="text-align:justify;">Entre os métodos, o filtro de Média apresentou maior borramento global à medida que o kernel cresce, sendo útil para reduzir ruído de baixa intensidade, mas com perda acentuada de nitidez. O Gaussiano trouxe um equilíbrio melhor entre suavização e preservação de contornos, porém ainda com borramento cumulativo em kernels grandes. O Bilateral destacou-se por suavizar áreas homogêneas preservando bordas, oferecendo o melhor compromisso visual quando se deseja redução de ruído sem perda de arestas. Já o filtro Mediana foi o mais eficaz contra ruído sal-e-pimenta, removendo impulsos sem comprometer tanto as bordas — especialmente com kernels pequenos e médios.</p>

<p style="text-align:justify;">Ao repetir as filtragens com ruído sal-e-pimenta, confirmou-se a superioridade da Mediana na limpeza desse tipo de ruído, enquanto o Bilateral manteve contornos nítidos com aparência natural. Com base nisso, para a aplicação em tempo real (webcam) selecionamos dois filtros e um tamanho de kernel representativos do melhor e do pior desempenho observados na etapa (2): a Mediana (ou Bilateral) com kernel moderado como melhor cenário (boa remoção de ruído com preservação de bordas) e a Média com kernel grande como pior cenário (suavização excessiva e perda de detalhes). O programa em OpenCV funcionou conforme o esperado, exibindo os resultados continuamente e permitindo o salvamento com a tecla “s”, atendendo aos requisitos propostos.</p>

<p style="text-align:justify;">De forma geral, recomenda-se utilizar o filtro Mediana para tratar ruídos impulsivos e o Bilateral quando for essencial preservar as bordas da imagem. O Gaussiano apresenta um bom equilíbrio entre suavização e nitidez, enquanto o filtro de Média deve ser aplicado com cuidado, pois tende a provocar borramento excessivo. A seleção do tamanho do kernel deve levar em conta a intensidade do ruído presente e o grau de fidelidade visual desejado na imagem final.</p>
      </div>
      </div>
      </details>
      
      
        <!-- RELATÓRIO 3 -->
  <details>
    <summary>Relatório 3</summary>
    <header class="content">
      <p><strong>Integrantes:</strong> Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier</p>
      <p><strong>Data:</strong> 22/10/2025</p>
    </header>
    <div class="content">
      <h3>1. Introdução</h3>
      <p style="text-align:justify;">O presente experimento tem como objetivo estudar a representação e conversão entre diferentes espaços de cores utilizando a biblioteca OpenCV. A compreensão desses espaços é essencial no processamento de imagens e visão computacional, pois muitas operações de segmentação, filtragem e detecção de objetos dependem da forma como as cores são representadas numericamente.</p>

 <p style="text-align:justify;">Inicialmente, são exploradas as principais conversões entre espaços de cores — como RGB ↔ GRAY, RGB ↔ YCrCb, RGB ↔ HSV e Bayer → RGB — por meio das funções de conversão de cor disponibilizadas pelo OpenCV. Em seguida, é realizado um experimento prático de mudança de espaço RGB para HSV, com captura em tempo real via webcam, permitindo observar o comportamento de diferentes objetos coloridos e aplicar a função inRange() para segmentar faixas específicas de cores.</p>

 <p style="text-align:justify;">Na sequência, o experimento é expandido com a aplicação de um filtro Gaussiano, comparando o efeito do pré-processamento na detecção de cores. Posteriormente, o detector de bordas Canny é implementado sobre as imagens filtradas, possibilitando analisar o impacto dos parâmetros de detecção e a resposta do sistema diante de diferentes objetos e níveis de ruído.</p>

 <p style="text-align:justify;">Por fim, são realizadas modificações adicionais para salvar imagens e gravar vídeos do processo de rastreamento, além da elaboração de um programa capaz de identificar múltiplas cores simultaneamente (como vermelho, verde e azul), consolidando os conceitos de espaço de cores, segmentação e detecção de bordas.</p>

 <p style="text-align:justify;">Essas etapas visam fortalecer o entendimento prático sobre a manipulação de imagens coloridas, destacando a importância da escolha adequada do espaço de cor e dos métodos de filtragem para aplicações de visão computacional em tempo real.</p>
 

      <section id="fundamentos-basicos" style="font-family: Arial, Helvetica, sans-serif; line-height: 1.6; color: #222; max-width: 900px; margin: 24px auto; background: #fff; padding: 24px; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,.06); text-align: justify;">
  <h3 style="margin-top:1;">2. Fundamentos Básicos</h3>
  <p>
    As imagens digitais são formadas por <strong>pixels</strong>, e cada pixel possui valores numéricos que representam a
    <strong>intensidade</strong> e a <strong>composição de cor</strong>. Esses valores são interpretados conforme o
    <strong>espaço de cores</strong> adotado — um modelo matemático que descreve como as cores são representadas e manipuladas
    em aplicações de processamento de imagem.
  </p>

  <h3>1) Espaço de Cores RGB</h3>
  <p>
    O espaço <strong>RGB (Red, Green, Blue)</strong> é o mais comum em câmeras e monitores, onde cada pixel é composto pela
    combinação dos três canais de cor. Embora intuitivo, o RGB não é ideal para todas as aplicações de visão computacional:
    pequenas variações de <em>iluminação</em> podem alterar significativamente os valores dos canais, dificultando a segmentação
    de cores específicas.
  </p>

  <h3>2) Espaço de Cores HSV</h3>
  <p>
    O modelo <strong>HSV (Hue, Saturation, Value)</strong> é frequentemente usado para <strong>segmentação e rastreamento de cores</strong>,
    pois separa as informações de <strong>matiz (Hue)</strong>, <strong>saturação (S)</strong> e <strong>valor/brilho (V)</strong>:
  </p>
  <ul style="margin-top: 8px;">
    <li><strong>Hue (Matiz):</strong> define a cor propriamente dita (vermelho, verde, azul etc.).</li>
    <li><strong>Saturation (Saturação):</strong> grau de pureza/intensidade da cor.</li>
    <li><strong>Value (Valor):</strong> brilho/luminosidade da cor.</li>
  </ul>
  <p>
    Essa separação torna o HSV mais <strong>robusto à variação de iluminação</strong>, facilitando a detecção de cores específicas por meio
    de limiares definidos com <code>inRange()</code> (OpenCV).
  </p>

  <h3>3) Conversões de Espaço de Cor</h3>
  <p>
    O OpenCV fornece funções diretas para conversão entre espaços de cor via <code>cvtColor()</code>. As conversões mais usadas
    neste laboratório incluem:
  </p>
  <ul style="margin-top: 8px;">
    <li><code>COLOR_BGR2GRAY</code> → converte imagem colorida para tons de cinza.</li>
    <li><code>COLOR_BGR2HSV</code> → converte para HSV (útil na segmentação por cor).</li>
    <li><code>COLOR_BGR2YCrCb</code> → separa luminância (Y) e crominância (Cr, Cb), útil em compressão de vídeo e detecção de pele.</li>
  </ul>

  <h3>4) Segmentação de Cores com <code>inRange()</code></h3>
  <p>
    A função <code>inRange()</code> realiza uma operação de <strong>limiarização</strong>, gerando uma máscara binária:
    pixels com HSV dentro da faixa definida (mín–máx) tornam-se <strong>brancos (255)</strong>; os demais, <strong>pretos (0)</strong>.
    Essa técnica é fundamental para <strong>isolar objetos coloridos</strong> e será usada nas etapas de detecção/rastreamento.
  </p>

  <h3>5) Filtragem Gaussiana</h3>
  <p>
    O <strong>filtro Gaussiano</strong> é um método de suavização que reduz ruídos de alta frequência, tornando bordas e áreas de cor
    mais homogêneas. Aplicá-lo <em>antes</em> da conversão para HSV ajuda a evitar que ruídos/reflexos causem erros na segmentação.
  </p>

  <h3>6) Detector de Bordas Canny</h3>
  <p>
    O <strong>detector de Canny</strong> identifica bordas analisando gradientes de intensidade. Ele combina suavização, cálculo de derivadas e
    limiares duplos, permitindo contornos <strong>nítidos e bem definidos</strong>. No contexto do laboratório, aplica-se o Canny sobre a imagem
    filtrada (Gaussiano) para visualizar contornos dos objetos segmentados.
  </p>

  <hr style="border:none; border-top:1px solid #ddd; margin: 20px 0;">

  <p style="font-size: 0.95rem;">
    <strong>Em síntese:</strong> a escolha adequada do espaço de cor (HSV, YCrCb etc.) e o uso combinado de
    <em>filtragem</em> (Gaussiano), <em>conversões</em> (cvtColor) e <em>detecção</em> (inRange, Canny) são decisivos para
    obter segmentações estáveis e contornos consistentes em aplicações de visão computacional em tempo real.
  </p>
</section>

      <section id="materiais-metodos" style="font-family: Arial, Helvetica, sans-serif; line-height: 1.6; color: #222; text-align: justify;">
  <h3>3. Materiais e Métodos</h3>
  <p>
    O experimento foi realizado em computador com Linux e webcam integrada, utilizando Python 3.10 e as bibliotecas OpenCV e NumPy.
    Investigou-se conversão de espaços de cor, filtragens e detecção de bordas em tempo real.
  </p>
  <p>
    O programa capturou frames da webcam (<code>cv.VideoCapture(0)</code>) e, opcionalmente, aplicou filtro Gaussiano
    (<code>cv.GaussianBlur</code>) para reduzir ruído antes da conversão de cor. Em seguida, a imagem foi convertida de
    RGB para HSV (<code>cv.cvtColor</code>), por ser mais estável à variação de iluminação e favorecer a segmentação.
  </p>
  <p>
    Para isolar regiões por cor, empregou-se <code>cv.inRange()</code> na faixa HSV definida; quando necessário, máscaras para múltiplas cores
    (p. ex., vermelho, verde e azul) foram combinadas por operações lógicas. Opcionalmente, aplicou-se o detector de bordas de Canny
    (<code>cv.Canny</code>) para realçar contornos.
  </p>
  <p>
    O sistema exibiu janelas com a imagem original, HSV, máscaras e bordas; imagens e vídeos puderam ser salvos via
    <code>cv.imwrite()</code> e <code>cv.VideoWriter()</code>. A execução foi encerrada ao pressionar a tecla <strong>q</strong>.
  </p>
</section>

      
<p><strong>Diagrama de bloco</strong></p>
<figure style="max-width: 720px; margin: 16px auto; text-align: center;">
  <img src="imagens/fluxograma_rel3.png"
       loading="lazy"
       style="width:60%; height:auto; border-radius:8px; border:1px solid #ccc;">
  <figcaption style="font:14px/1.4 Arial, sans-serif; color:#00000; margin-top:8px;">
    Diagrama de blocos representando o fluxo de execução do programa de conversão de cores, filtragem e detecção de bordas no OpenCV
  </figcaption>
</figure>
      
      <h3>4. Resultados e Análises</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>5. Conclusões</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
    </div>
    </div>
  </details>
    
      <!-- RELATÓRIO 4 -->
  <details>
    <summary>Relatório 4</summary>
    <header class="content">
      <p><strong>Integrantes:</strong> Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier</p>
      <p><strong>Data:</strong> X/X/2025</p>
    </header>
    <div class="content">
      <h3>1. Introdução</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 2...</p>
      <h3>2. Fundamentos Básicos</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>3. Materiais e Métodos</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>4. Resultados e Análises</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>5. Conclusões</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
    </div>
    </div>
  </details>

      <!-- RELATÓRIO 5 -->
  <details>
    <summary>Relatório 5</summary>
    <header class="content">
      <p><strong>Integrantes:</strong> Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier</p>
      <p><strong>Data:</strong> X/X/2025</p>
    </header>
    <div class="content">
      <h3>1. Introdução</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 2...</p>
      <h3>2. Fundamentos Básicos</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>3. Materiais e Métodos</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>4. Resultados e Análises</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>5. Conclusões</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
    </div>
    </div>
  </details>
  
        <!-- RELATÓRIO 6 -->
  <details>
    <summary>Relatório 6</summary>
    <header class="content">
      <p><strong>Integrantes:</strong> Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier</p>
      <p><strong>Data:</strong> X/X/2025</p>
    </header>
    <div class="content">
      <h3>1. Introdução</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 2...</p>
      <h3>2. Fundamentos Básicos</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>3. Materiais e Métodos</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>4. Resultados e Análises</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>5. Conclusões</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
    </div>
    </div>
  </details>

      <!-- RELATÓRIO 7 -->
  <details>
    <summary>Relatório 7</summary>
    <header class="content">
      <p><strong>Integrantes:</strong> Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier</p>
      <p><strong>Data:</strong> X/X/2025</p>
    </header>
    <div class="content">
      <h3>1. Introdução</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 2...</p>
      <h3>2. Fundamentos Básicos</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>3. Materiais e Métodos</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>4. Resultados e Análises</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>5. Conclusões</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
    </div>
    </div>
  </details>
  
      <!-- RELATÓRIO 8 -->
  <details>
    <summary>Relatório 8</summary>
    <header class="content">
      <p><strong>Integrantes:</strong> Fernanda Ayumi Kuroiwa — Gabriel Henrique Pensado Rothen — Ingrid Mara Xavier</p>
      <p><strong>Data:</strong> X/X/2025</p>
    </header>
    <div class="content">
      <h3>1. Introdução</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 2...</p>
      <h3>2. Fundamentos Básicos</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>3. Materiais e Métodos</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>4. Resultados e Análises</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
      <h3>5. Conclusões</h3>
      <p style="text-align:justify;">Resumo do objetivo do Relatório 3...</p>
    </div>
    </div>
  </details>  
  
      <div class="back-top"><a href="#topo">↑ Voltar ao topo</a></div>
  </section>
  
  <footer class="footer">
    © 2025 — Equipe RoadWatch
  </footer>
</body>
</html>
